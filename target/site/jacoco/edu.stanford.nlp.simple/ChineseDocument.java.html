<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>ChineseDocument.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">Stanford CoreNLP</a> &gt; <a href="index.source.html" class="el_package">edu.stanford.nlp.simple</a> &gt; <span class="el_source">ChineseDocument.java</span></div><h1>ChineseDocument.java</h1><pre class="source lang-java linenums">package edu.stanford.nlp.simple;

import edu.stanford.nlp.io.IOUtils;
import edu.stanford.nlp.io.RuntimeIOException;
import edu.stanford.nlp.pipeline.*;
import edu.stanford.nlp.util.Lazy;

import java.io.IOException;
import java.util.List;
import java.util.Properties;

/**
 * A sentence running with the Chinese models.
 *
 * @author &lt;a href=&quot;mailto:angeli@cs.stanford.edu&quot;&gt;Gabor Angeli&lt;/a&gt;
 */
public class ChineseDocument extends Document {

  /**
   * The default {@link ChineseSegmenterAnnotator} implementation
   */
<span class="nc" id="L22">  private static final Lazy&lt;Annotator&gt; chineseSegmenter = Lazy.of(() -&gt; new ChineseSegmenterAnnotator(&quot;segment&quot;, new Properties() {{</span>
<span class="nc" id="L23">    setProperty(&quot;segment.model&quot;, &quot;edu/stanford/nlp/models/segmenter/chinese/ctb.gz&quot;);</span>
<span class="nc" id="L24">    setProperty(&quot;segment.sighanCorporaDict&quot;, &quot;edu/stanford/nlp/models/segmenter/chinese&quot;);</span>
<span class="nc" id="L25">    setProperty(&quot;segment.serDictionary&quot;, &quot;edu/stanford/nlp/models/segmenter/chinese/dict-chris6.ser.gz&quot;);</span>
<span class="nc" id="L26">    setProperty(&quot;segment.sighanPostProcessing&quot;, &quot;true&quot;);</span>
<span class="nc" id="L27">  }}));</span>

  /**
   * The empty {@link java.util.Properties} object, for use with creating default annotators.
   */
<span class="nc" id="L32">  static final Properties EMPTY_PROPS = new Properties() {{</span>
    try {
<span class="nc" id="L34">      load(IOUtils.getInputStreamFromURLOrClasspathOrFileSystem(&quot;edu/stanford/nlp/pipeline/StanfordCoreNLP-chinese.properties&quot;));</span>
<span class="nc" id="L35">    } catch (IOException e) {</span>
<span class="nc" id="L36">      throw new RuntimeIOException(e);</span>
<span class="nc" id="L37">    }</span>
<span class="nc" id="L38">    setProperty(&quot;language&quot;, &quot;chinese&quot;);</span>
<span class="nc" id="L39">    setProperty(&quot;annotators&quot;, &quot;&quot;);</span>
<span class="nc" id="L40">    setProperty(&quot;parse.binaryTrees&quot;, &quot;true&quot;);</span>
<span class="nc" id="L41">  }};</span>

  /**
   * Create a new document from the passed in text.
   * @param text The text of the document.
   */
  public ChineseDocument(String text) {
<span class="nc" id="L48">    super(ChineseDocument.EMPTY_PROPS, text);</span>
<span class="nc" id="L49">  }</span>

  /**
   * Convert a CoreNLP Annotation object to a Document.
   * @param ann The CoreNLP Annotation object.
   */
  @SuppressWarnings(&quot;Convert2streamapi&quot;)
  public ChineseDocument(Annotation ann) {
<span class="nc" id="L57">    super(ChineseDocument.EMPTY_PROPS, ann);</span>
<span class="nc" id="L58">  }</span>


  /**
   * Create a Document object from a read Protocol Buffer.
   * @see edu.stanford.nlp.simple.Document#serialize()
   * @param proto The protocol buffer representing this document.
   */
  public ChineseDocument(CoreNLPProtos.Document proto) {
<span class="nc" id="L67">    super(ChineseDocument.EMPTY_PROPS, proto);</span>
<span class="nc" id="L68">  }</span>

  /**
   * Create a new chinese document from the passed in text and the given properties.
   * @param text The text of the document.
   */
  protected ChineseDocument(Properties props, String text) {
<span class="nc" id="L75">    super(props, text);</span>
<span class="nc" id="L76">  }</span>


  /** {@inheritDoc} */
  @Override
  public List&lt;Sentence&gt; sentences(Properties props) {
<span class="nc" id="L82">    return this.sentences(props, chineseSegmenter.get());</span>
  }


  /**
&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD
   * No lemma annotator for Chinese -- set the lemma to be the word.
   *
   * @see Document#runLemma(Properties)
   */
  @Override
  protected Document runLemma(Properties props) {
<span class="nc" id="L94">    return mockLemma(props);</span>
  }


  /**
   * No sentiment analysis implemented for Chinese.
   *
   * @see Document#runSentiment(Properties)
   */
  @Override
  protected Document runSentiment(Properties props) {
<span class="nc" id="L105">    throw new IllegalArgumentException(&quot;Sentiment analysis is not implemented for Chinese&quot;);</span>
  }

  /**
   * The Neural Dependency Parser doesn't support Chinese yet, so back off to running the
   * constituency parser instead.
   */
  @Override  // TODO(danqi; from Gabor): remove this method when we have a trained NNDep model
  Document runDepparse(Properties props) {
<span class="nc" id="L114">    return runParse(props);</span>
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.7.8.201612092310</span></div></body></html>