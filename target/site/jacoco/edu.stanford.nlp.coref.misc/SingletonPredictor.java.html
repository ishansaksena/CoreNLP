<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>SingletonPredictor.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">Stanford CoreNLP</a> &gt; <a href="index.source.html" class="el_package">edu.stanford.nlp.coref.misc</a> &gt; <span class="el_source">SingletonPredictor.java</span></div><h1>SingletonPredictor.java</h1><pre class="source lang-java linenums">// StanfordCoreNLP -- a suite of NLP tools

package edu.stanford.nlp.coref.misc;

import java.io.IOException;
import java.io.ObjectOutputStream;
import java.util.ArrayList;
import java.util.Map;
import java.util.Properties;

import edu.stanford.nlp.classify.Dataset;
import edu.stanford.nlp.classify.GeneralDataset;
import edu.stanford.nlp.classify.LogisticClassifier;
import edu.stanford.nlp.classify.LogisticClassifierFactory;
import edu.stanford.nlp.coref.data.CorefCluster;
import edu.stanford.nlp.coref.data.Dictionaries;
import edu.stanford.nlp.coref.data.Document;
import edu.stanford.nlp.coref.data.DocumentMaker;
import edu.stanford.nlp.coref.data.Mention;
import edu.stanford.nlp.io.IOUtils;
import edu.stanford.nlp.io.RuntimeIOException;
import edu.stanford.nlp.ling.BasicDatum;
import edu.stanford.nlp.ling.CoreAnnotations.SentencesAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations.TokenBeginAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations.TokensAnnotation;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.ling.IndexedWord;
import edu.stanford.nlp.semgraph.SemanticGraph;
import edu.stanford.nlp.util.CoreMap;
import edu.stanford.nlp.util.PropertiesUtils;
import edu.stanford.nlp.util.StringUtils;
import edu.stanford.nlp.util.logging.Redwood;

/**
 * Train the singleton predictor using a logistic regression classifier as
 * described in Recasens, de Marneffe and Potts, NAACL 2013
 * Label 0 = Singleton mention.
 * Label 1 = Coreferent mention.
 *
 * This is an example of the properties file for this class:
 *
 *     # This is set to true so that gold POS, gold parses and gold NEs are used.
 *     dcoref.replicate.conll = true
 *
 *     # Path to the directory containing the CoNLL training files.
 *     dcoref.conll2011 = /path/to/conll-2012/v4/data/train/data/english/annotations/
 *
 *     # Output file where the serialized model is saved.
 *     singleton.predictor.output = /path/to/predictor.output
 *
 * @author Marta Recasens
 * @author Marie-Catherine de Marneffe
 */
public class SingletonPredictor  {

  /** A logger for this class */
<span class="nc" id="L57">  private static final Redwood.RedwoodChannels log = Redwood.channels(SingletonPredictor.class);</span>

<span class="nc" id="L59">  private SingletonPredictor() {} // static main utility</span>

  /**
   * Set index for each token and sentence in the document.
   * @param doc
   */
  private static void setTokenIndices(Document doc) {
<span class="nc" id="L66">    int token_index = 0;</span>
<span class="nc bnc" id="L67" title="All 2 branches missed.">    for (CoreMap sent : doc.annotation.get(SentencesAnnotation.class)) {</span>
<span class="nc bnc" id="L68" title="All 2 branches missed.">      for (CoreLabel token : sent.get(TokensAnnotation.class)) {</span>
<span class="nc" id="L69">        token.set(TokenBeginAnnotation.class, token_index++);</span>
<span class="nc" id="L70">      }</span>
<span class="nc" id="L71">    }</span>
<span class="nc" id="L72">  }</span>

  /**
   * Generate the training features from the CoNLL input file.
   * @return Dataset of feature vectors
   * @throws Exception
   */
  private static GeneralDataset&lt;String, String&gt; generateFeatureVectors(Properties props) throws Exception {

<span class="nc" id="L81">    GeneralDataset&lt;String, String&gt; dataset = new Dataset&lt;&gt;();</span>

<span class="nc" id="L83">    Dictionaries dict = new Dictionaries(props);</span>
<span class="nc" id="L84">    DocumentMaker docMaker = new DocumentMaker(props, dict);</span>

    Document document;
<span class="nc bnc" id="L87" title="All 2 branches missed.">    while((document = docMaker.nextDoc()) != null){</span>
<span class="nc" id="L88">      setTokenIndices(document);</span>
<span class="nc" id="L89">      Map&lt;Integer, CorefCluster&gt; entities = document.goldCorefClusters;</span>

      // Generate features for coreferent mentions with class label 1
<span class="nc bnc" id="L92" title="All 2 branches missed.">      for(CorefCluster entity : entities.values()){</span>
<span class="nc bnc" id="L93" title="All 2 branches missed.">        for(Mention mention : entity.getCorefMentions()){</span>
          // Ignore verbal mentions
<span class="nc bnc" id="L95" title="All 2 branches missed.">          if(mention.headWord.tag().startsWith(&quot;V&quot;)) continue;</span>

<span class="nc" id="L97">          IndexedWord head = mention.enhancedDependency.</span>
<span class="nc" id="L98">              getNodeByIndexSafe(mention.headWord.index());</span>
<span class="nc bnc" id="L99" title="All 2 branches missed.">          if(head == null) continue;</span>
<span class="nc" id="L100">          ArrayList&lt;String&gt; feats = mention.getSingletonFeatures(dict);</span>
<span class="nc" id="L101">          dataset.add(new BasicDatum&lt;&gt;(feats, &quot;1&quot;));</span>
<span class="nc" id="L102">        }</span>
<span class="nc" id="L103">      }</span>

      // Generate features for singletons with class label 0
<span class="nc" id="L106">      ArrayList&lt;CoreLabel&gt; gold_heads = new ArrayList&lt;&gt;();</span>
<span class="nc bnc" id="L107" title="All 2 branches missed.">      for(Mention gold_men : document.goldMentionsByID.values()){</span>
<span class="nc" id="L108">        gold_heads.add(gold_men.headWord);</span>
<span class="nc" id="L109">      }</span>
<span class="nc bnc" id="L110" title="All 2 branches missed.">      for(Mention predicted_men : document.predictedMentionsByID.values()){</span>
<span class="nc" id="L111">        SemanticGraph dep = predicted_men.enhancedDependency;</span>
<span class="nc" id="L112">        IndexedWord head = dep.getNodeByIndexSafe(predicted_men.headWord.index());</span>
<span class="nc bnc" id="L113" title="All 4 branches missed.">        if(head == null || !dep.vertexSet().contains(head)) continue;</span>

        // Ignore verbal mentions
<span class="nc bnc" id="L116" title="All 2 branches missed.">        if(predicted_men.headWord.tag().startsWith(&quot;V&quot;)) continue;</span>
        // If the mention is in the gold set, it is not a singleton and thus ignore
<span class="nc bnc" id="L118" title="All 2 branches missed.">        if(gold_heads.contains(predicted_men.headWord)) continue;</span>

<span class="nc" id="L120">        dataset.add(new BasicDatum&lt;&gt;(</span>
<span class="nc" id="L121">                predicted_men.getSingletonFeatures(dict), &quot;0&quot;));</span>
<span class="nc" id="L122">      }</span>
<span class="nc" id="L123">    }</span>

<span class="nc" id="L125">    dataset.summaryStatistics();</span>
<span class="nc" id="L126">    return dataset;</span>
  }

  /**
   * Train the singleton predictor using a logistic regression classifier.
   * @param pDataset Dataset of features
   * @return Singleton predictor
   */
  public static LogisticClassifier&lt;String, String&gt; train(GeneralDataset&lt;String, String&gt; pDataset){
<span class="nc" id="L135">    LogisticClassifierFactory&lt;String, String&gt; lcf =</span>
            new LogisticClassifierFactory&lt;&gt;();
<span class="nc" id="L137">    LogisticClassifier&lt;String, String&gt; classifier = lcf.trainClassifier(pDataset);</span>

<span class="nc" id="L139">    return classifier;</span>
  }

  /**
   * Saves the singleton predictor model to the given filename.
   * If there is an error, a RuntimeIOException is thrown.
   */
  private static void saveToSerialized(LogisticClassifier&lt;String, String&gt; predictor,
                                       String filename) {
    try {
<span class="nc" id="L149">      log.info(&quot;Writing singleton predictor in serialized format to file &quot; + filename + ' ');</span>
<span class="nc" id="L150">      ObjectOutputStream out = IOUtils.writeStreamFromString(filename);</span>
<span class="nc" id="L151">      out.writeObject(predictor);</span>
<span class="nc" id="L152">      out.close();</span>
<span class="nc" id="L153">      log.info(&quot;done.&quot;);</span>
<span class="nc" id="L154">    } catch (IOException ioe) {</span>
<span class="nc" id="L155">      throw new RuntimeIOException(ioe);</span>
<span class="nc" id="L156">    }</span>
<span class="nc" id="L157">  }</span>

  private static String getPathSingletonPredictor(Properties props) {
<span class="nc" id="L160">    return PropertiesUtils.getString(props, &quot;coref.path.singletonPredictor&quot;, &quot;edu/stanford/nlp/models/dcoref/singleton.predictor.ser&quot;);</span>
  }

  public static void main(String[] args) throws Exception {
    Properties props;
<span class="nc bnc" id="L165" title="All 2 branches missed.">    if (args.length &gt; 0) {</span>
<span class="nc" id="L166">      props = StringUtils.argsToProperties(args);</span>
    } else {
<span class="nc" id="L168">      props = new Properties();</span>
    }
<span class="nc bnc" id="L170" title="All 2 branches missed.">    if ( ! props.containsKey(&quot;dcoref.conll2011&quot;)) {</span>
<span class="nc" id="L171">      log.info(&quot;-dcoref.conll2011 [input_CoNLL_corpus]: was not specified&quot;);</span>
<span class="nc" id="L172">      return;</span>
    }
<span class="nc bnc" id="L174" title="All 2 branches missed.">    if ( ! props.containsKey(&quot;singleton.predictor.output&quot;)) {</span>
<span class="nc" id="L175">      log.info(&quot;-singleton.predictor.output [output_model_file]: was not specified&quot;);</span>
<span class="nc" id="L176">      return;</span>
    }

<span class="nc" id="L179">    GeneralDataset&lt;String, String&gt; data = SingletonPredictor.generateFeatureVectors(props);</span>
<span class="nc" id="L180">    LogisticClassifier&lt;String, String&gt; classifier = SingletonPredictor.train(data);</span>
<span class="nc" id="L181">    SingletonPredictor.saveToSerialized(classifier, getPathSingletonPredictor(props));</span>
<span class="nc" id="L182">  }</span>

}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.7.8.201612092310</span></div></body></html>