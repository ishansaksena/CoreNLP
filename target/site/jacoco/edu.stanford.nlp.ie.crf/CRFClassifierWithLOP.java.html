<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>CRFClassifierWithLOP.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">Stanford CoreNLP</a> &gt; <a href="index.source.html" class="el_package">edu.stanford.nlp.ie.crf</a> &gt; <span class="el_source">CRFClassifierWithLOP.java</span></div><h1>CRFClassifierWithLOP.java</h1><pre class="source lang-java linenums">// CRFClassifier -- a probabilistic (CRF) sequence model, mainly used for NER.
// Copyright (c) 2002-2008 The Board of Trustees of
// The Leland Stanford Junior University. All Rights Reserved.
//
// This program is free software; you can redistribute it and/or
// modify it under the terms of the GNU General Public License
// as published by the Free Software Foundation; either version 2
// of the License, or (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.
//
// You should have received a copy of the GNU General Public License
// along with this program; if not, write to the Free Software
// Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
//
// For more information, bug reports, fixes, contact:
//    Christopher Manning
//    Dept of Computer Science, Gates 1A
//    Stanford CA 94305-9010
//    USA
//    Support/Questions: java-nlp-user@lists.stanford.edu
//    Licensing: java-nlp-support@lists.stanford.edu

package edu.stanford.nlp.ie.crf; 
import edu.stanford.nlp.util.logging.Redwood;

import edu.stanford.nlp.io.IOUtils;
import edu.stanford.nlp.math.ArrayMath;
import edu.stanford.nlp.optimization.*;
import edu.stanford.nlp.sequences.*;
import edu.stanford.nlp.util.*;

import java.io.*;
import java.util.*;
import java.util.zip.GZIPInputStream;

/**
 * Subclass of {@link edu.stanford.nlp.ie.crf.CRFClassifier} for learning Logarithmic Opinion Pools.

 * @author Mengqiu Wang
 */
<span class="nc bnc" id="L45" title="All 2 branches missed.">public class CRFClassifierWithLOP&lt;IN extends CoreMap&gt; extends CRFClassifier&lt;IN&gt;  {</span>

  /** A logger for this class */
<span class="nc" id="L48">  private static Redwood.RedwoodChannels log = Redwood.channels(CRFClassifierWithLOP.class);</span>

  List&lt;Set&lt;Integer&gt;&gt; featureIndicesSetArray;
  List&lt;List&lt;Integer&gt;&gt; featureIndicesListArray;

  protected CRFClassifierWithLOP() {
<span class="nc" id="L54">    super(new SeqClassifierFlags());</span>
<span class="nc" id="L55">  }</span>

  public CRFClassifierWithLOP(Properties props) {
<span class="nc" id="L58">    super(props);</span>
<span class="nc" id="L59">  }</span>

  public CRFClassifierWithLOP(SeqClassifierFlags flags) {
<span class="nc" id="L62">    super(flags);</span>
<span class="nc" id="L63">  }</span>

  private int[][][][] createPartialDataForLOP(int lopIter, int[][][][] data) {
<span class="nc" id="L66">    ArrayList&lt;Integer&gt; newFeatureList = new ArrayList&lt;&gt;(1000);</span>
<span class="nc" id="L67">    Set&lt;Integer&gt; featureIndicesSet = featureIndicesSetArray.get(lopIter);</span>

<span class="nc" id="L69">    int[][][][] newData = new int[data.length][][][];</span>
<span class="nc bnc" id="L70" title="All 2 branches missed.">    for (int i = 0; i &lt; data.length; i++) {</span>
<span class="nc" id="L71">      newData[i] = new int[data[i].length][][];</span>
<span class="nc bnc" id="L72" title="All 2 branches missed.">      for (int j = 0; j &lt; data[i].length; j++) {</span>
<span class="nc" id="L73">        newData[i][j] = new int[data[i][j].length][];</span>
<span class="nc bnc" id="L74" title="All 2 branches missed.">        for (int k = 0; k &lt; data[i][j].length; k++) {</span>
<span class="nc" id="L75">          int[] oldFeatures = data[i][j][k];</span>
<span class="nc" id="L76">          newFeatureList.clear();</span>
<span class="nc bnc" id="L77" title="All 2 branches missed.">          for (int oldFeatureIndex : oldFeatures) {</span>
<span class="nc bnc" id="L78" title="All 2 branches missed.">            if (featureIndicesSet.contains(oldFeatureIndex)) {</span>
<span class="nc" id="L79">              newFeatureList.add(oldFeatureIndex);</span>
            }
          }
<span class="nc" id="L82">          newData[i][j][k] = new int[newFeatureList.size()];</span>
<span class="nc bnc" id="L83" title="All 2 branches missed.">          for (int l = 0; l &lt; newFeatureList.size(); ++l) {</span>
<span class="nc" id="L84">            newData[i][j][k][l] = newFeatureList.get(l);</span>
          }
        }
      }
    }

<span class="nc" id="L90">    return newData;</span>
  }

  private void getFeatureBoundaryIndices(int numFeatures, int numLopExpert) {
    // first find begin/end feature index for each expert
<span class="nc" id="L95">    int interval = numFeatures / numLopExpert;</span>
<span class="nc" id="L96">    featureIndicesSetArray = new ArrayList&lt;&gt;(numLopExpert);</span>
<span class="nc" id="L97">    featureIndicesListArray = new ArrayList&lt;&gt;(numLopExpert);</span>
<span class="nc bnc" id="L98" title="All 2 branches missed.">    for (int i = 0; i &lt; numLopExpert; i++) {</span>
<span class="nc" id="L99">      featureIndicesSetArray.add(Generics.&lt;Integer&gt;newHashSet(interval));</span>
<span class="nc" id="L100">      featureIndicesListArray.add(Generics.&lt;Integer&gt;newArrayList(interval));</span>
    }
<span class="nc bnc" id="L102" title="All 2 branches missed.">    if (flags.randomLopFeatureSplit) {</span>
<span class="nc bnc" id="L103" title="All 2 branches missed.">      for (int fIndex = 0; fIndex &lt; numFeatures; fIndex++) {</span>
<span class="nc" id="L104">        int lopIter = random.nextInt(numLopExpert);</span>
<span class="nc" id="L105">        featureIndicesSetArray.get(lopIter).add(fIndex);</span>
<span class="nc" id="L106">        featureIndicesListArray.get(lopIter).add(fIndex);</span>
      }
    } else {
<span class="nc bnc" id="L109" title="All 2 branches missed.">      for (int lopIter = 0; lopIter &lt; numLopExpert; lopIter++) {</span>
<span class="nc" id="L110">        int beginIndex = lopIter * interval;</span>
<span class="nc" id="L111">        int endIndex = (lopIter+1) * interval;</span>
<span class="nc bnc" id="L112" title="All 2 branches missed.">        if (lopIter == numLopExpert - 1) {</span>
<span class="nc" id="L113">          endIndex = numFeatures;</span>
        }
<span class="nc bnc" id="L115" title="All 2 branches missed.">        for (int fIndex = beginIndex; fIndex &lt; endIndex; fIndex++) {</span>
<span class="nc" id="L116">          featureIndicesSetArray.get(lopIter).add(fIndex);</span>
<span class="nc" id="L117">          featureIndicesListArray.get(lopIter).add(fIndex);</span>
        }
      }
    }
<span class="nc bnc" id="L121" title="All 2 branches missed.">    for (int lopIter = 0; lopIter &lt; numLopExpert; lopIter++) {</span>
<span class="nc" id="L122">      Collections.sort(featureIndicesListArray.get(lopIter));</span>
    }
<span class="nc" id="L124">  }</span>

  @Override
  protected double[] trainWeights(int[][][][] data, int[][] labels, Evaluator[] evaluators, int pruneFeatureItr, double[][][][] featureVals) {
<span class="nc" id="L128">    int numFeatures = featureIndex.size();</span>
<span class="nc" id="L129">    int numLopExpert = flags.numLopExpert;</span>
<span class="nc" id="L130">    double[][] lopExpertWeights = new double[numLopExpert][];</span>

<span class="nc" id="L132">    getFeatureBoundaryIndices(numFeatures, numLopExpert);</span>

<span class="nc bnc" id="L134" title="All 2 branches missed.">    if (flags.initialLopWeights != null) {</span>
      try {
<span class="nc" id="L136">        log.info(&quot;Reading initial LOP weights from file &quot; + flags.initialLopWeights + &quot; ...&quot;);</span>
<span class="nc" id="L137">        BufferedReader br = IOUtils.readerFromString(flags.initialLopWeights);</span>
<span class="nc" id="L138">        List&lt;double[]&gt; listOfWeights = new ArrayList&lt;&gt;(numLopExpert);</span>
<span class="nc bnc" id="L139" title="All 2 branches missed.">        for (String line; (line = br.readLine()) != null; ) {</span>
<span class="nc" id="L140">          line = line.trim();</span>
<span class="nc" id="L141">          String[] parts = line.split(&quot;\t&quot;);</span>
<span class="nc" id="L142">          double[] wArr = new double[parts.length];</span>
<span class="nc bnc" id="L143" title="All 2 branches missed.">          for (int i = 0; i &lt; parts.length; i++) {</span>
<span class="nc" id="L144">            wArr[i] = Double.parseDouble(parts[i]);</span>
          }
<span class="nc" id="L146">          listOfWeights.add(wArr);</span>
<span class="nc" id="L147">        }</span>
<span class="nc bnc" id="L148" title="All 4 branches missed.">        assert(listOfWeights.size() == numLopExpert);</span>
<span class="nc" id="L149">        log.info(&quot;Done!&quot;);</span>
<span class="nc bnc" id="L150" title="All 2 branches missed.">        for (int i = 0; i &lt; numLopExpert; i++)</span>
<span class="nc" id="L151">          lopExpertWeights[i] = listOfWeights.get(i);</span>
        // DataInputStream dis = new DataInputStream(new BufferedInputStream(new GZIPInputStream(new FileInputStream(
        //     flags.initialLopWeights))));
        // initialScales = Convert.readDoubleArr(dis);
<span class="nc" id="L155">      } catch (IOException e) {</span>
<span class="nc" id="L156">        throw new RuntimeException(&quot;Could not read from double initial LOP weights file &quot; + flags.initialLopWeights);</span>
<span class="nc" id="L157">      }</span>
    } else {
<span class="nc bnc" id="L159" title="All 2 branches missed.">      for (int lopIter = 0; lopIter &lt; numLopExpert; lopIter++) {</span>
<span class="nc" id="L160">        int[][][][] partialData = createPartialDataForLOP(lopIter, data);</span>
<span class="nc bnc" id="L161" title="All 2 branches missed.">        if (flags.randomLopWeights) {</span>
<span class="nc" id="L162">          lopExpertWeights[lopIter] = super.getObjectiveFunction(partialData, labels).initial();</span>
        } else {
<span class="nc" id="L164">          lopExpertWeights[lopIter] = super.trainWeights(partialData, labels, evaluators, pruneFeatureItr, null);</span>
        }
      }
<span class="nc bnc" id="L167" title="All 2 branches missed.">      if (flags.includeFullCRFInLOP) {</span>
<span class="nc" id="L168">        double[][] newLopExpertWeights = new double[numLopExpert+1][];</span>
<span class="nc" id="L169">        System.arraycopy(lopExpertWeights, 0, newLopExpertWeights, 0, lopExpertWeights.length);</span>
<span class="nc bnc" id="L170" title="All 2 branches missed.">        if (flags.randomLopWeights) {</span>
<span class="nc" id="L171">          newLopExpertWeights[numLopExpert] = super.getObjectiveFunction(data, labels).initial();</span>
        } else {
<span class="nc" id="L173">          newLopExpertWeights[numLopExpert] = super.trainWeights(data, labels, evaluators, pruneFeatureItr, null);</span>
        }

<span class="nc" id="L176">        Set&lt;Integer&gt; newSet = Generics.newHashSet(numFeatures);</span>
<span class="nc" id="L177">        List&lt;Integer&gt; newList = new ArrayList&lt;&gt;(numFeatures);</span>
<span class="nc bnc" id="L178" title="All 2 branches missed.">        for (int fIndex = 0; fIndex &lt; numFeatures; fIndex++) {</span>
<span class="nc" id="L179">          newSet.add(fIndex);</span>
<span class="nc" id="L180">          newList.add(fIndex);</span>
        }
<span class="nc" id="L182">        featureIndicesSetArray.add(newSet);</span>
<span class="nc" id="L183">        featureIndicesListArray.add(newList);</span>

<span class="nc" id="L185">        numLopExpert += 1;</span>
<span class="nc" id="L186">        lopExpertWeights = newLopExpertWeights;</span>
      }
    }

    // Dumb scales
    // double[] lopScales = new double[numLopExpert];
    // Arrays.fill(lopScales, 1.0);
<span class="nc" id="L193">    CRFLogConditionalObjectiveFunctionForLOP func = new CRFLogConditionalObjectiveFunctionForLOP(data, labels, lopExpertWeights,</span>
        windowSize, classIndex, labelIndices, map, flags.backgroundSymbol, numLopExpert, featureIndicesSetArray, featureIndicesListArray,
        flags.backpropLopTraining);
<span class="nc" id="L196">    cliquePotentialFunctionHelper = func;</span>

<span class="nc" id="L198">    Minimizer&lt;DiffFunction&gt; minimizer = getMinimizer(0, evaluators);</span>

    double[] initialScales;
    //TODO(mengqiu) clean this part up when backpropLogTraining == true
<span class="nc bnc" id="L202" title="All 2 branches missed.">    if (flags.initialLopScales == null) {</span>
<span class="nc" id="L203">      initialScales = func.initial();</span>
    } else {
      try {
<span class="nc" id="L206">        log.info(&quot;Reading initial LOP scales from file &quot; + flags.initialLopScales);</span>
<span class="nc" id="L207">        DataInputStream dis = new DataInputStream(new BufferedInputStream(new GZIPInputStream(new FileInputStream(</span>
            flags.initialLopScales))));
<span class="nc" id="L209">        initialScales = ConvertByteArray.readDoubleArr(dis);</span>
<span class="nc" id="L210">      } catch (IOException e) {</span>
<span class="nc" id="L211">        throw new RuntimeException(&quot;Could not read from double initial LOP scales file &quot; + flags.initialLopScales);</span>
<span class="nc" id="L212">      }</span>
    }

<span class="nc" id="L215">    double[] learnedParams = minimizer.minimize(func, flags.tolerance, initialScales);</span>
<span class="nc" id="L216">    double[] rawScales = func.separateLopScales(learnedParams);</span>
<span class="nc" id="L217">    double[] lopScales = ArrayMath.softmax(rawScales);</span>
<span class="nc" id="L218">    log.info(&quot;After SoftMax Transformation, learned scales are:&quot;);</span>
<span class="nc bnc" id="L219" title="All 2 branches missed.">    for (int lopIter = 0; lopIter &lt; numLopExpert; lopIter++) {</span>
<span class="nc" id="L220">      log.info(&quot;lopScales[&quot; + lopIter + &quot;] = &quot; + lopScales[lopIter]);</span>
    }
<span class="nc" id="L222">    double[][] learnedLopExpertWeights = lopExpertWeights;</span>
<span class="nc bnc" id="L223" title="All 2 branches missed.">    if (flags.backpropLopTraining) {</span>
<span class="nc" id="L224">      learnedLopExpertWeights = func.separateLopExpertWeights(learnedParams);</span>
    }
<span class="nc" id="L226">    return CRFLogConditionalObjectiveFunctionForLOP.combineAndScaleLopWeights(numLopExpert, learnedLopExpertWeights, lopScales);</span>
  }

} // end class CRFClassifierWithLOP
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.7.8.201612092310</span></div></body></html>