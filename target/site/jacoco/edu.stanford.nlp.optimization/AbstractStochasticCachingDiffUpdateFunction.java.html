<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>AbstractStochasticCachingDiffUpdateFunction.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">Stanford CoreNLP</a> &gt; <a href="index.source.html" class="el_package">edu.stanford.nlp.optimization</a> &gt; <span class="el_source">AbstractStochasticCachingDiffUpdateFunction.java</span></div><h1>AbstractStochasticCachingDiffUpdateFunction.java</h1><pre class="source lang-java linenums">package edu.stanford.nlp.optimization;

/**
 * Function for stochastic calculations that does update in place
 * (instead of maintaining and returning the derivative).
 *
 * Weights are represented by an array of doubles and a scalar
 * that indicates how much to scale all weights by.
 * This allows all weights to be scaled by just modifying the scalar.
 *
 * @author Angel Chang
 */
<span class="fc" id="L13">public abstract class AbstractStochasticCachingDiffUpdateFunction</span>
        extends AbstractStochasticCachingDiffFunction {

<span class="fc" id="L16">  protected boolean skipValCalc = false;</span>

  /**
   * Gets a random sample (this is sampling with replacement).
   *
   * @param sampleSize number of samples to generate
   * @return array of indices for random sample of sampleSize
   */
  public int[] getSample(int sampleSize) {
<span class="nc" id="L25">    int[] sample = new int[sampleSize];</span>
<span class="nc bnc" id="L26" title="All 2 branches missed.">    for (int i = 0; i &lt; sampleSize; i++) {</span>
<span class="nc" id="L27">      sample[i] = randGenerator.nextInt(this.dataDimension()); // Just generate a random index</span>
    }
<span class="nc" id="L29">    return sample;</span>
  }

  /**
   * Computes value of function for specified value of x (scaled by xScale)
   * only over samples indexed by batch.
   *
   * @param x unscaled weights
   * @param xScale how much to scale x by when performing calculations
   * @param batch indices of which samples to compute function over
   * @return value of function at specified x (scaled by xScale) for samples
   */
  public abstract double valueAt(double[] x, double xScale, int[] batch);

  public double valueAt(double[] x, double xScale, int batchSize) {
<span class="nc" id="L44">    getBatch(batchSize);</span>
<span class="nc" id="L45">    return valueAt(x, xScale, thisBatch);</span>
  }

  /**
   * Performs stochastic update of weights x (scaled by xScale) based
   * on samples indexed by batch.
   *
   * @param x unscaled weights
   * @param xScale how much to scale x by when performing calculations
   * @param batch indices of which samples to compute function over
   * @param gain how much to scale adjustments to x
   * @return value of function at specified x (scaled by xScale) for samples
   */
  public abstract double calculateStochasticUpdate(double[] x, double xScale, int[] batch, double gain);

  /**
   * Performs stochastic update of weights x (scaled by xScale) based
   * on next batch of batchSize.
   *
   * @param x unscaled weights
   * @param xScale how much to scale x by when performing calculations
   * @param batchSize number of samples to pick next
   * @param gain how much to scale adjustments to x
   * @return value of function at specified x (scaled by xScale) for samples
   */
  public double calculateStochasticUpdate(double[] x, double xScale, int batchSize, double gain) {
<span class="nc" id="L71">    getBatch(batchSize);</span>
<span class="nc" id="L72">    return calculateStochasticUpdate(x, xScale, thisBatch, gain);</span>
  }

  /**
   * Performs stochastic gradient calculation based
   * on samples indexed by batch and does not apply regularization.
   * Does not update the parameter values.
   * Typically stores derivative information for later access.
   *
   * @param x Unscaled weights
   * @param batch Indices of which samples to compute function over
   */
  public abstract void calculateStochasticGradient(double[] x, int[] batch);

  /**
   * Performs stochastic gradient updates based
   * on samples indexed by batch and do not apply regularization.
   *
   * @param x unscaled weights
   * @param batchSize number of samples to pick next
   */
  public void calculateStochasticGradient(double[] x, int batchSize) {
<span class="nc" id="L94">    getBatch(batchSize);</span>
<span class="nc" id="L95">    calculateStochasticGradient(x, thisBatch);</span>
<span class="nc" id="L96">  }</span>

}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.7.8.201612092310</span></div></body></html>