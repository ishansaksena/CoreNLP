<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>NaiveBayesClassifier.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">Stanford CoreNLP</a> &gt; <a href="index.source.html" class="el_package">edu.stanford.nlp.classify</a> &gt; <span class="el_source">NaiveBayesClassifier.java</span></div><h1>NaiveBayesClassifier.java</h1><pre class="source lang-java linenums">// Stanford Classifier - a multiclass maxent classifier
// NaiveBayesClassifier
// Copyright (c) 2003-2007 The Board of Trustees of
// The Leland Stanford Junior University. All Rights Reserved.
//
// This program is free software; you can redistribute it and/or
// modify it under the terms of the GNU General Public License
// as published by the Free Software Foundation; either version 2
// of the License, or (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.
//
// You should have received a copy of the GNU General Public License
// along with this program; if not, write to the Free Software
// Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
//
// For more information, bug reports, fixes, contact:
//    Christopher Manning
//    Dept of Computer Science, Gates 1A
//    Stanford CA 94305-9010
//    USA
//    Support/Questions: java-nlp-user@lists.stanford.edu
//    Licensing: java-nlp-support@lists.stanford.edu
//    http://www-nlp.stanford.edu/software/classifier.shtml

package edu.stanford.nlp.classify;

import edu.stanford.nlp.ling.Datum;
import edu.stanford.nlp.ling.RVFDatum;
import edu.stanford.nlp.stats.ClassicCounter;
import edu.stanford.nlp.stats.Counter;
import edu.stanford.nlp.stats.Counters;
import edu.stanford.nlp.util.Pair;

import java.io.PrintStream;
import java.util.Iterator;
import java.util.Set;
import java.util.Collection;


import edu.stanford.nlp.util.logging.Redwood;

/**
 * A Naive Bayes classifier with a fixed number of features.
 * The features are assumed to have integer values even though RVFDatum will return doubles.
 *
 * @author Kristina Toutanova (kristina@cs.stanford.edu)
 * @author Sarah Spikes (sdspikes@cs.stanford.edu) - Templatization.  Not sure what the weights counter
 *         is supposed to hold; given the weights function it seems to hold {@code Pair&lt;Pair&lt;L, F&gt;, Object&gt;}
 *         but this seems like a strange thing to expect to be passed in.
 */
public class NaiveBayesClassifier&lt;L, F&gt; implements Classifier&lt;L, F&gt;, RVFClassifier&lt;L, F&gt; {

  private static final long serialVersionUID = 1544820342684024068L;

  private Counter&lt;Pair&lt;Pair&lt;L, F&gt;, Number&gt;&gt; weights; //the keys will be class and feature and value
  private Counter&lt;L&gt; priors;
  private Set&lt;F&gt; features; // we need all features to add the weights for zero-valued ones
  private boolean addZeroValued; // whether to add features as having value 0 if they are not in Datum/RFVDatum
  private Counter&lt;L&gt; priorZero; //if we need to add the zeros, pre-compute the weight for all zeros for each class
  private Set&lt;L&gt; labels;
<span class="nc" id="L65">  private final Integer zero = Integer.valueOf(0);</span>

<span class="nc" id="L67">  final static Redwood.RedwoodChannels logger = Redwood.channels(NaiveBayesClassifier.class);</span>

  public Collection&lt;L&gt; labels() {
<span class="nc" id="L70">    return labels;</span>
  }

  public L classOf(RVFDatum&lt;L, F&gt; example) {
<span class="nc" id="L74">    Counter&lt;L&gt; scores = scoresOf(example);</span>
<span class="nc" id="L75">    return Counters.argmax(scores);</span>
  }

  public ClassicCounter&lt;L&gt; scoresOf(RVFDatum&lt;L, F&gt; example) {
<span class="nc" id="L79">    ClassicCounter&lt;L&gt; scores = new ClassicCounter&lt;&gt;();</span>
<span class="nc" id="L80">    Counters.addInPlace(scores, priors);</span>
<span class="nc bnc" id="L81" title="All 2 branches missed.">    if (addZeroValued) {</span>
<span class="nc" id="L82">      Counters.addInPlace(scores, priorZero);</span>
    }
<span class="nc bnc" id="L84" title="All 2 branches missed.">    for (L l : labels) {</span>
<span class="nc" id="L85">      double score = 0.0;</span>
<span class="nc" id="L86">      Counter&lt;F&gt; features = example.asFeaturesCounter();</span>
<span class="nc bnc" id="L87" title="All 2 branches missed.">      for (F f : features.keySet()) {</span>
<span class="nc" id="L88">        int value = (int) features.getCount(f);</span>
<span class="nc" id="L89">        score += weight(l, f, Integer.valueOf(value));</span>
<span class="nc bnc" id="L90" title="All 2 branches missed.">        if (addZeroValued) {</span>
<span class="nc" id="L91">          score -= weight(l, f, zero);</span>
        }
<span class="nc" id="L93">      }</span>
<span class="nc" id="L94">      scores.incrementCount(l, score);</span>
<span class="nc" id="L95">    }</span>
<span class="nc" id="L96">    return scores;</span>
  }


  public L classOf(Datum&lt;L, F&gt; example) {
<span class="nc" id="L101">    RVFDatum&lt;L, F&gt; rvf = new RVFDatum&lt;&gt;(example);</span>
<span class="nc" id="L102">    return classOf(rvf);</span>
  }

  public ClassicCounter&lt;L&gt; scoresOf(Datum&lt;L, F&gt; example) {
<span class="nc" id="L106">    RVFDatum&lt;L, F&gt; rvf = new RVFDatum&lt;&gt;(example);</span>
<span class="nc" id="L107">    return scoresOf(rvf);</span>
  }

<span class="nc" id="L110">  public NaiveBayesClassifier(Counter&lt;Pair&lt;Pair&lt;L, F&gt;, Number&gt;&gt; weights, Counter&lt;L&gt; priors, Set&lt;L&gt; labels, Set&lt;F&gt; features, boolean addZero) {</span>
<span class="nc" id="L111">    this.weights = weights;</span>
<span class="nc" id="L112">    this.features = features;</span>
<span class="nc" id="L113">    this.priors = priors;</span>
<span class="nc" id="L114">    this.labels = labels;</span>
<span class="nc" id="L115">    addZeroValued = addZero;</span>
<span class="nc bnc" id="L116" title="All 2 branches missed.">    if (addZeroValued) {</span>
<span class="nc" id="L117">      initZeros();</span>
    }
<span class="nc" id="L119">  }</span>


  public float accuracy(Iterator&lt;RVFDatum&lt;L, F&gt;&gt; exampleIterator) {
<span class="nc" id="L123">    int correct = 0;</span>
<span class="nc" id="L124">    int total = 0;</span>
<span class="nc bnc" id="L125" title="All 2 branches missed.">    for (; exampleIterator.hasNext();) {</span>
<span class="nc" id="L126">      RVFDatum&lt;L, F&gt; next = exampleIterator.next();</span>
<span class="nc" id="L127">      L guess = classOf(next);</span>
<span class="nc bnc" id="L128" title="All 2 branches missed.">      if (guess.equals(next.label())) {</span>
<span class="nc" id="L129">        correct++;</span>
      }
<span class="nc" id="L131">      total++;</span>
<span class="nc" id="L132">    }</span>
<span class="nc" id="L133">    logger.info(&quot;correct &quot; + correct + &quot; out of &quot; + total);</span>
<span class="nc" id="L134">    return correct / (float) total;</span>
  }

  public void print(PrintStream pw) {
<span class="nc" id="L138">    pw.println(&quot;priors &quot;);</span>
<span class="nc" id="L139">    pw.println(priors.toString());</span>
<span class="nc" id="L140">    pw.println(&quot;weights &quot;);</span>
<span class="nc" id="L141">    pw.println(weights.toString());</span>
<span class="nc" id="L142">  }</span>

  public void print() {
<span class="nc" id="L145">    print(System.out);</span>
<span class="nc" id="L146">  }</span>

  private double weight(L label, F feature, Number val) {
<span class="nc" id="L149">    Pair&lt;Pair&lt;L, F&gt;, Number&gt; p = new Pair&lt;&gt;(new Pair&lt;&gt;(label, feature), val);</span>
<span class="nc" id="L150">    double v = weights.getCount(p);</span>
<span class="nc" id="L151">    return v;</span>
  }

  public NaiveBayesClassifier(Counter&lt;Pair&lt;Pair&lt;L, F&gt;, Number&gt;&gt; weights, Counter&lt;L&gt; priors, Set&lt;L&gt; labels) {
<span class="nc" id="L155">    this(weights, priors, labels, null, false);</span>
<span class="nc" id="L156">  }</span>

  /**
   * In case the features for which there is a value 0 in an example need to have their coefficients multiplied in,
   * we need to pre-compute the addition
   * priorZero(l)=sum_{features} wt(l,feat=0)
   */
  private void initZeros() {
<span class="nc" id="L164">    priorZero = new ClassicCounter&lt;&gt;();</span>
<span class="nc bnc" id="L165" title="All 2 branches missed.">    for (L label : labels) {</span>
<span class="nc" id="L166">      double score = 0;</span>
<span class="nc bnc" id="L167" title="All 2 branches missed.">      for (F feature : features) {</span>
<span class="nc" id="L168">        score += weight(label, feature, zero);</span>
<span class="nc" id="L169">      }</span>
<span class="nc" id="L170">      priorZero.setCount(label, score);</span>
<span class="nc" id="L171">    }</span>
<span class="nc" id="L172">  }</span>


}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.7.8.201612092310</span></div></body></html>