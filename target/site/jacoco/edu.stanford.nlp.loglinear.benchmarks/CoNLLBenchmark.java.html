<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>CoNLLBenchmark.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">Stanford CoreNLP</a> &gt; <a href="index.source.html" class="el_package">edu.stanford.nlp.loglinear.benchmarks</a> &gt; <span class="el_source">CoNLLBenchmark.java</span></div><h1>CoNLLBenchmark.java</h1><pre class="source lang-java linenums">package edu.stanford.nlp.loglinear.benchmarks; 
import edu.stanford.nlp.util.logging.Redwood;

import edu.stanford.nlp.loglinear.inference.CliqueTree;
import edu.stanford.nlp.loglinear.learning.AbstractBatchOptimizer;
import edu.stanford.nlp.loglinear.learning.BacktrackingAdaGradOptimizer;
import edu.stanford.nlp.loglinear.learning.LogLikelihoodDifferentiableFunction;
import edu.stanford.nlp.loglinear.model.ConcatVector;
import edu.stanford.nlp.loglinear.model.ConcatVectorNamespace;
import edu.stanford.nlp.loglinear.model.GraphicalModel;

import java.io.*;
import java.util.*;
import java.util.zip.GZIPInputStream;
import java.util.zip.GZIPOutputStream;

/**
 * Created on 8/26/15.
 * @author keenon
 * &lt;p&gt;
 * This loads the CoNLL dataset and 300 dimensional google word embeddings and trains a model on the data using binary
 * and unary factors. This is a nice explanation of why it is key to have ConcatVector as a datastructure, since there
 * is no need to specify the number of words in advance anywhere, and data structures will happily resize with a minimum
 * of GCC wastage.
 */
<span class="nc bnc" id="L26" title="All 2 branches missed.">public class CoNLLBenchmark   {</span>

  /** A logger for this class */
<span class="nc" id="L29">  private static Redwood.RedwoodChannels log = Redwood.channels(CoNLLBenchmark.class);</span>

  static final String DATA_PATH = &quot;/u/nlp/data/ner/conll/&quot;;

<span class="nc" id="L33">  Map&lt;String, double[]&gt; embeddings = new HashMap&lt;&gt;();</span>

  public static void main(String[] args) throws Exception {
<span class="nc" id="L36">    new CoNLLBenchmark().benchmarkOptimizer();</span>
<span class="nc" id="L37">  }</span>

  public void benchmarkOptimizer() throws Exception {
<span class="nc" id="L40">    List&lt;CoNLLSentence&gt; train = getSentences(DATA_PATH + &quot;conll.iob.4class.train&quot;);</span>
<span class="nc" id="L41">    List&lt;CoNLLSentence&gt; testA = getSentences(DATA_PATH + &quot;conll.iob.4class.testa&quot;);</span>
<span class="nc" id="L42">    List&lt;CoNLLSentence&gt; testB = getSentences(DATA_PATH + &quot;conll.iob.4class.testb&quot;);</span>

<span class="nc" id="L44">    List&lt;CoNLLSentence&gt; allData = new ArrayList&lt;&gt;();</span>
<span class="nc" id="L45">    allData.addAll(train);</span>
<span class="nc" id="L46">    allData.addAll(testA);</span>
<span class="nc" id="L47">    allData.addAll(testB);</span>

<span class="nc" id="L49">    Set&lt;String&gt; tagsSet = new HashSet&lt;&gt;();</span>
<span class="nc bnc" id="L50" title="All 4 branches missed.">    for (CoNLLSentence sentence : allData) for (String nerTag : sentence.ner) tagsSet.add(nerTag);</span>
<span class="nc" id="L51">    List&lt;String&gt; tags = new ArrayList&lt;&gt;();</span>
<span class="nc" id="L52">    tags.addAll(tagsSet);</span>

<span class="nc" id="L54">    embeddings = getEmbeddings(DATA_PATH + &quot;google-300-trimmed.ser.gz&quot;, allData);</span>

<span class="nc" id="L56">    log.info(&quot;Making the training set...&quot;);</span>

<span class="nc" id="L58">    ConcatVectorNamespace namespace = new ConcatVectorNamespace();</span>

<span class="nc" id="L60">    int trainSize = train.size();</span>
<span class="nc" id="L61">    GraphicalModel[] trainingSet = new GraphicalModel[trainSize];</span>
<span class="nc bnc" id="L62" title="All 2 branches missed.">    for (int i = 0; i &lt; trainSize; i++) {</span>
<span class="nc bnc" id="L63" title="All 2 branches missed.">      if (i % 10 == 0) {</span>
<span class="nc" id="L64">        log.info(i + &quot;/&quot; + trainSize);</span>
      }
<span class="nc" id="L66">      trainingSet[i] = generateSentenceModel(namespace, train.get(i), tags);</span>
    }

<span class="nc" id="L69">    log.info(&quot;Training system...&quot;);</span>

<span class="nc" id="L71">    AbstractBatchOptimizer opt = new BacktrackingAdaGradOptimizer();</span>

    // This training call is basically what we want the benchmark for. It should take 99% of the wall clock time
<span class="nc" id="L74">    ConcatVector weights = opt.optimize(trainingSet, new LogLikelihoodDifferentiableFunction(), namespace.newWeightsVector(), 0.01, 1.0e-5, false);</span>

<span class="nc" id="L76">    log.info(&quot;Testing system...&quot;);</span>

    // Evaluation method lifted from the CoNLL 2004 perl script

<span class="nc" id="L80">    Map&lt;String, Double&gt; correctChunk = new HashMap&lt;&gt;();</span>
<span class="nc" id="L81">    Map&lt;String, Double&gt; foundCorrect = new HashMap&lt;&gt;();</span>
<span class="nc" id="L82">    Map&lt;String, Double&gt; foundGuessed = new HashMap&lt;&gt;();</span>
<span class="nc" id="L83">    double correct = 0.0;</span>
<span class="nc" id="L84">    double total = 0.0;</span>

<span class="nc bnc" id="L86" title="All 2 branches missed.">    for (CoNLLSentence sentence : testA) {</span>
<span class="nc" id="L87">      GraphicalModel model = generateSentenceModel(namespace, sentence, tags);</span>
<span class="nc" id="L88">      int[] guesses = new CliqueTree(model, weights).calculateMAP();</span>
<span class="nc" id="L89">      String[] nerGuesses = new String[guesses.length];</span>
<span class="nc bnc" id="L90" title="All 2 branches missed.">      for (int i = 0; i &lt; guesses.length; i++) {</span>
<span class="nc" id="L91">        nerGuesses[i] = tags.get(guesses[i]);</span>
<span class="nc bnc" id="L92" title="All 2 branches missed.">        if (nerGuesses[i].equals(sentence.ner.get(i))) {</span>
<span class="nc" id="L93">          correct++;</span>
<span class="nc" id="L94">          correctChunk.put(nerGuesses[i], correctChunk.getOrDefault(nerGuesses[i], 0.) + 1);</span>
        }
<span class="nc" id="L96">        total++;</span>
<span class="nc" id="L97">        foundCorrect.put(sentence.ner.get(i), foundCorrect.getOrDefault(sentence.ner.get(i), 0.) + 1);</span>
<span class="nc" id="L98">        foundGuessed.put(nerGuesses[i], foundGuessed.getOrDefault(nerGuesses[i], 0.) + 1);</span>
      }
<span class="nc" id="L100">    }</span>

<span class="nc" id="L102">    log.info(&quot;\nSystem results:\n&quot;);</span>

<span class="nc" id="L104">    log.info(&quot;Accuracy: &quot; + (correct / total) + &quot;\n&quot;);</span>

<span class="nc bnc" id="L106" title="All 2 branches missed.">    for (String tag : tags) {</span>
<span class="nc bnc" id="L107" title="All 2 branches missed.">      double precision = foundGuessed.getOrDefault(tag, 0.0) == 0 ? 0.0 : correctChunk.getOrDefault(tag, 0.0) / foundGuessed.get(tag);</span>
<span class="nc bnc" id="L108" title="All 2 branches missed.">      double recall = foundCorrect.getOrDefault(tag, 0.0) == 0 ? 0.0 : correctChunk.getOrDefault(tag, 0.0) / foundCorrect.get(tag);</span>
<span class="nc bnc" id="L109" title="All 2 branches missed.">      double f1 = (precision + recall == 0.0) ? 0.0 : (precision * recall * 2) / (precision + recall);</span>
<span class="nc" id="L110">      log.info(tag + &quot; (&quot; + foundCorrect.getOrDefault(tag, 0.0).intValue() + &quot;)&quot;);</span>
<span class="nc" id="L111">      log.info(&quot;\tP:&quot; + precision + &quot; (&quot; + correctChunk.getOrDefault(tag, 0.0).intValue() + &quot;/&quot; + foundGuessed.getOrDefault(tag, 0.0).intValue() + &quot;)&quot;);</span>
<span class="nc" id="L112">      log.info(&quot;\tR:&quot; + recall + &quot; (&quot; + correctChunk.getOrDefault(tag, 0.0).intValue() + &quot;/&quot; + foundCorrect.getOrDefault(tag, 0.0).intValue() + &quot;)&quot;);</span>
<span class="nc" id="L113">      log.info(&quot;\tF1:&quot; + f1);</span>
<span class="nc" id="L114">    }</span>
<span class="nc" id="L115">  }</span>

  ////////////////////////////////////////////////////////////////////////////////////////////
  // GENERATING MODELS
  ////////////////////////////////////////////////////////////////////////////////////////////

  private static String getWordShape(String string) {
<span class="nc bnc" id="L122" title="All 4 branches missed.">    if (string.toUpperCase().equals(string) &amp;&amp; string.toLowerCase().equals(string)) return &quot;no-case&quot;;</span>
<span class="nc bnc" id="L123" title="All 2 branches missed.">    if (string.toUpperCase().equals(string)) return &quot;upper-case&quot;;</span>
<span class="nc bnc" id="L124" title="All 2 branches missed.">    if (string.toLowerCase().equals(string)) return &quot;lower-case&quot;;</span>
<span class="nc bnc" id="L125" title="All 6 branches missed.">    if (string.length() &gt; 1 &amp;&amp; Character.isUpperCase(string.charAt(0)) &amp;&amp; string.substring(1).toLowerCase().equals(string.substring(1)))</span>
<span class="nc" id="L126">      return &quot;capitalized&quot;;</span>
<span class="nc" id="L127">    return &quot;mixed-case&quot;;</span>
  }

  public GraphicalModel generateSentenceModel(ConcatVectorNamespace namespace, CoNLLSentence sentence, List&lt;String&gt; tags) {
<span class="nc" id="L131">    GraphicalModel model = new GraphicalModel();</span>

<span class="nc bnc" id="L133" title="All 2 branches missed.">    for (int i = 0; i &lt; sentence.token.size(); i++) {</span>

      // Add the training label

<span class="nc" id="L137">      Map&lt;String, String&gt; metadata = model.getVariableMetaDataByReference(i);</span>

<span class="nc" id="L139">      metadata.put(LogLikelihoodDifferentiableFunction.VARIABLE_TRAINING_VALUE, &quot;&quot; + tags.indexOf(sentence.ner.get(i)));</span>

<span class="nc" id="L141">      metadata.put(&quot;TOKEN&quot;, &quot;&quot; + sentence.token.get(i));</span>
<span class="nc" id="L142">      metadata.put(&quot;POS&quot;, &quot;&quot; + sentence.pos.get(i));</span>
<span class="nc" id="L143">      metadata.put(&quot;CHUNK&quot;, &quot;&quot; + sentence.npchunk.get(i));</span>
<span class="nc" id="L144">      metadata.put(&quot;TAG&quot;, &quot;&quot; + sentence.ner.get(i));</span>
    }

<span class="nc" id="L147">    CoNLLFeaturizer.annotate(model, tags, namespace, embeddings);</span>

<span class="nc bnc" id="L149" title="All 4 branches missed.">    assert (model.factors != null);</span>
<span class="nc bnc" id="L150" title="All 2 branches missed.">    for (GraphicalModel.Factor f : model.factors) {</span>
<span class="nc bnc" id="L151" title="All 4 branches missed.">      assert (f != null);</span>
<span class="nc" id="L152">    }</span>

<span class="nc" id="L154">    return model;</span>
  }

  ////////////////////////////////////////////////////////////////////////////////////////////
  // LOADING DATA FROM FILES
  ////////////////////////////////////////////////////////////////////////////////////////////

<span class="nc" id="L161">  public static class CoNLLSentence {</span>
<span class="nc" id="L162">    public List&lt;String&gt; token = new ArrayList&lt;&gt;();</span>
<span class="nc" id="L163">    public List&lt;String&gt; ner = new ArrayList&lt;&gt;();</span>
<span class="nc" id="L164">    public List&lt;String&gt; pos = new ArrayList&lt;&gt;();</span>
<span class="nc" id="L165">    public List&lt;String&gt; npchunk = new ArrayList&lt;&gt;();</span>

<span class="nc" id="L167">    public CoNLLSentence(List&lt;String&gt; token, List&lt;String&gt; ner, List&lt;String&gt; pos, List&lt;String&gt; npchunk) {</span>
<span class="nc" id="L168">      this.token = token;</span>
<span class="nc" id="L169">      this.ner = ner;</span>
<span class="nc" id="L170">      this.pos = pos;</span>
<span class="nc" id="L171">      this.npchunk = npchunk;</span>
<span class="nc" id="L172">    }</span>
  }

  public List&lt;CoNLLSentence&gt; getSentences(String filename) throws IOException {
<span class="nc" id="L176">    List&lt;CoNLLSentence&gt; sentences = new ArrayList&lt;&gt;();</span>

<span class="nc" id="L178">    List&lt;String&gt; tokens = new ArrayList&lt;&gt;();</span>
<span class="nc" id="L179">    List&lt;String&gt; ner = new ArrayList&lt;&gt;();</span>
<span class="nc" id="L180">    List&lt;String&gt; pos = new ArrayList&lt;&gt;();</span>
<span class="nc" id="L181">    List&lt;String&gt; npchunk = new ArrayList&lt;&gt;();</span>

<span class="nc" id="L183">    BufferedReader br = new BufferedReader(new FileReader(filename));</span>

    String line;
<span class="nc bnc" id="L186" title="All 2 branches missed.">    while ((line = br.readLine()) != null) {</span>
<span class="nc" id="L187">      String[] parts = line.split(&quot;\t&quot;);</span>
<span class="nc bnc" id="L188" title="All 2 branches missed.">      if (parts.length == 4) {</span>
<span class="nc" id="L189">        tokens.add(parts[0]);</span>
<span class="nc" id="L190">        pos.add(parts[1]);</span>
<span class="nc" id="L191">        npchunk.add(parts[2]);</span>
<span class="nc" id="L192">        String tag = parts[3];</span>
<span class="nc bnc" id="L193" title="All 2 branches missed.">        if (tag.contains(&quot;-&quot;)) {</span>
<span class="nc" id="L194">          ner.add(tag.split(&quot;-&quot;)[1]);</span>
        } else {
<span class="nc" id="L196">          ner.add(tag);</span>
        }
<span class="nc bnc" id="L198" title="All 2 branches missed.">        if (parts[0].equals(&quot;.&quot;)) {</span>
<span class="nc" id="L199">          sentences.add(new CoNLLSentence(tokens, ner, pos, npchunk));</span>
<span class="nc" id="L200">          tokens = new ArrayList&lt;&gt;();</span>
<span class="nc" id="L201">          ner = new ArrayList&lt;&gt;();</span>
<span class="nc" id="L202">          pos = new ArrayList&lt;&gt;();</span>
<span class="nc" id="L203">          npchunk = new ArrayList&lt;&gt;();</span>
        }
      }
<span class="nc" id="L206">    }</span>

<span class="nc" id="L208">    return sentences;</span>
  }

  @SuppressWarnings(&quot;unchecked&quot;)
  public Map&lt;String, double[]&gt; getEmbeddings(String cacheFilename, List&lt;CoNLLSentence&gt; sentences) throws IOException, ClassNotFoundException {
<span class="nc" id="L213">    File f = new File(cacheFilename);</span>
    Map&lt;String, double[]&gt; trimmedSet;

<span class="nc bnc" id="L216" title="All 2 branches missed.">    if (!f.exists()) {</span>
<span class="nc" id="L217">      trimmedSet = new HashMap&lt;&gt;();</span>

<span class="nc" id="L219">      Map&lt;String, double[]&gt; massiveSet = loadEmbeddingsFromFile(&quot;../google-300.txt&quot;);</span>
<span class="nc" id="L220">      log.info(&quot;Got massive embedding set size &quot; + massiveSet.size());</span>

<span class="nc bnc" id="L222" title="All 2 branches missed.">      for (CoNLLSentence sentence : sentences) {</span>
<span class="nc bnc" id="L223" title="All 2 branches missed.">        for (String token : sentence.token) {</span>
<span class="nc bnc" id="L224" title="All 2 branches missed.">          if (massiveSet.containsKey(token)) {</span>
<span class="nc" id="L225">            trimmedSet.put(token, massiveSet.get(token));</span>
          }
<span class="nc" id="L227">        }</span>
<span class="nc" id="L228">      }</span>
<span class="nc" id="L229">      log.info(&quot;Got trimmed embedding set size &quot; + trimmedSet.size());</span>

<span class="nc" id="L231">      f.createNewFile();</span>
<span class="nc" id="L232">      ObjectOutputStream oos = new ObjectOutputStream(new GZIPOutputStream(new FileOutputStream(cacheFilename)));</span>
<span class="nc" id="L233">      oos.writeObject(trimmedSet);</span>
<span class="nc" id="L234">      oos.close();</span>

<span class="nc" id="L236">      log.info(&quot;Wrote trimmed set to file&quot;);</span>
<span class="nc" id="L237">    } else {</span>
<span class="nc" id="L238">      ObjectInputStream ois = new ObjectInputStream(new GZIPInputStream(new FileInputStream(cacheFilename)));</span>
<span class="nc" id="L239">      trimmedSet = (Map&lt;String, double[]&gt;) ois.readObject();</span>
    }

<span class="nc" id="L242">    return trimmedSet;</span>
  }

  public Map&lt;String, double[]&gt; loadEmbeddingsFromFile(String filename) throws IOException {
<span class="nc" id="L246">    Map&lt;String, double[]&gt; embeddings = new HashMap&lt;&gt;();</span>

<span class="nc" id="L248">    BufferedReader br = new BufferedReader(new FileReader(filename));</span>

<span class="nc" id="L250">    int readLines = 0;</span>

<span class="nc" id="L252">    String line = br.readLine();</span>
<span class="nc bnc" id="L253" title="All 2 branches missed.">    while ((line = br.readLine()) != null) {</span>
<span class="nc" id="L254">      String[] parts = line.split(&quot; &quot;);</span>

<span class="nc bnc" id="L256" title="All 2 branches missed.">      if (parts.length == 302) {</span>
<span class="nc" id="L257">        String token = parts[0];</span>
<span class="nc" id="L258">        double[] embedding = new double[300];</span>
<span class="nc bnc" id="L259" title="All 2 branches missed.">        for (int i = 1; i &lt; parts.length - 1; i++) {</span>
<span class="nc" id="L260">          embedding[i - 1] = Double.parseDouble(parts[i]);</span>
        }
<span class="nc" id="L262">        embeddings.put(token, embedding);</span>
      }

<span class="nc" id="L265">      readLines++;</span>
<span class="nc bnc" id="L266" title="All 2 branches missed.">      if (readLines % 10000 == 0) {</span>
<span class="nc" id="L267">        log.info(&quot;Read &quot; + readLines + &quot; lines&quot;);</span>
      }
<span class="nc" id="L269">    }</span>

<span class="nc" id="L271">    return embeddings;</span>
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.7.8.201612092310</span></div></body></html>