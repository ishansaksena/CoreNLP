<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>AceReader.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">Stanford CoreNLP</a> &gt; <a href="index.source.html" class="el_package">edu.stanford.nlp.ie.machinereading.domains.ace</a> &gt; <span class="el_source">AceReader.java</span></div><h1>AceReader.java</h1><pre class="source lang-java linenums">package edu.stanford.nlp.ie.machinereading.domains.ace; 
import edu.stanford.nlp.util.logging.Redwood;

import java.io.File;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.Set;
import java.util.logging.Level;
import java.util.logging.Logger;

import javax.xml.parsers.ParserConfigurationException;

import org.xml.sax.SAXException;

import edu.stanford.nlp.ie.machinereading.GenericDataSetReader;
import edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceCharSeq;
import edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceDocument;
import edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceEntity;
import edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceEntityMention;
import edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceEventMention;
import edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceRelationMention;
import edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceRelationMentionArgument;
import edu.stanford.nlp.ie.machinereading.domains.ace.reader.AceToken;
import edu.stanford.nlp.ie.machinereading.structure.AnnotationUtils;
import edu.stanford.nlp.ie.machinereading.structure.EntityMention;
import edu.stanford.nlp.ie.machinereading.structure.EventMention;
import edu.stanford.nlp.ie.machinereading.structure.ExtractionObject;
import edu.stanford.nlp.ie.machinereading.structure.MachineReadingAnnotations;
import edu.stanford.nlp.ie.machinereading.structure.RelationMention;
import edu.stanford.nlp.ie.machinereading.structure.Span;
import edu.stanford.nlp.io.IOUtils;
import edu.stanford.nlp.ling.CoreAnnotations;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.pipeline.Annotation;
import edu.stanford.nlp.pipeline.StanfordCoreNLP;
import edu.stanford.nlp.stats.ClassicCounter;
import edu.stanford.nlp.stats.Counter;
import edu.stanford.nlp.util.CoreMap;
import edu.stanford.nlp.util.Generics;
import edu.stanford.nlp.util.StringUtils;

/**
 *
 * Simple wrapper of Mihai's ACE code to ie.machinereading.structure objects.
 *
 * @author David McClosky
 *
 */
<span class="nc bnc" id="L53" title="All 2 branches missed.">public class AceReader extends GenericDataSetReader  {</span>

  /** A logger for this class */
<span class="nc" id="L56">  private static Redwood.RedwoodChannels log = Redwood.channels(AceReader.class);</span>

  private final Counter&lt;String&gt; entityCounts;
  private final Counter&lt;String&gt; adjacentEntityMentions;
  private final Counter&lt;String&gt; relationCounts;
  private final Counter&lt;String&gt; nameRelationCounts;
  private final Counter&lt;String&gt; eventCounts;
  private final Counter&lt;String&gt; mentionTypeCounts;
  private final String aceVersion;
  private static final boolean VERBOSE = false;

  /**
   * Make an AceReader.
   */
  public AceReader() {
<span class="nc" id="L71">    this(null, true);</span>
<span class="nc" id="L72">  }</span>

  public AceReader(StanfordCoreNLP processor, boolean preprocess) {
<span class="nc" id="L75">    this(processor, preprocess, &quot;ACE2005&quot;);</span>
<span class="nc" id="L76">  }</span>

  public AceReader(StanfordCoreNLP processor, boolean preprocess, String version) {
<span class="nc" id="L79">    super(processor, preprocess, false, true);</span>

<span class="nc" id="L81">    entityCounts = new ClassicCounter&lt;&gt;();</span>
<span class="nc" id="L82">    adjacentEntityMentions = new ClassicCounter&lt;&gt;();</span>
<span class="nc" id="L83">    nameRelationCounts = new ClassicCounter&lt;&gt;();</span>
<span class="nc" id="L84">    relationCounts = new ClassicCounter&lt;&gt;();</span>
<span class="nc" id="L85">    eventCounts = new ClassicCounter&lt;&gt;();</span>
<span class="nc" id="L86">    mentionTypeCounts = new ClassicCounter&lt;&gt;();</span>

<span class="nc" id="L88">    logger = Logger.getLogger(AceReader.class.getName());</span>
    // run quietly by default
<span class="nc" id="L90">    logger.setLevel(Level.SEVERE);</span>

<span class="nc" id="L92">    aceVersion = version;</span>
<span class="nc" id="L93">  }</span>

  /**
   * Reads in ACE*.apf.xml files and converts them to RelationSentence objects.
   * Note that you probably should call parse() instead.
   *
   * Currently, this ignores document boundaries (the list returned will include
   * sentences from all documents).
   *
   * @param path directory containing ACE files to read (e.g.
   *          &quot;/home/mcclosky/scr/data/ACE2005/english_test&quot;). This can also be
   *          the path to a single file. *
   * @return list of RelationSentence objects
   */
  @Override
  public Annotation read(String path) throws IOException, SAXException, ParserConfigurationException {
<span class="nc" id="L109">    List&lt;CoreMap&gt; allSentences = new ArrayList&lt;&gt;();</span>
<span class="nc" id="L110">    File basePath = new File(path);</span>
<span class="nc bnc" id="L111" title="All 4 branches missed.">    assert basePath.exists();</span>
<span class="nc" id="L112">    Annotation corpus = new Annotation(&quot;&quot;);</span>

<span class="nc bnc" id="L114" title="All 2 branches missed.">    if (basePath.isDirectory()) {</span>
<span class="nc bnc" id="L115" title="All 2 branches missed.">      for (File aceFile : IOUtils.iterFilesRecursive(basePath, &quot;.apf.xml&quot;)) {</span>
<span class="nc bnc" id="L116" title="All 2 branches missed.">        if (aceFile.getName().endsWith(&quot;.UPC1.apf.xml&quot;)) {</span>
<span class="nc" id="L117">          continue;</span>
        }
<span class="nc" id="L119">        allSentences.addAll(readDocument(aceFile, corpus));</span>
<span class="nc" id="L120">      }</span>
    } else {
      // in case it's a file
<span class="nc" id="L123">      allSentences.addAll(readDocument(basePath, corpus));</span>
    }

<span class="nc" id="L126">    AnnotationUtils.addSentences(corpus, allSentences);</span>

    // quick stats
    if (VERBOSE) {
      printCounter(entityCounts, &quot;entity mention&quot;);
      printCounter(relationCounts, &quot;relation mention&quot;);
      printCounter(eventCounts, &quot;event mention&quot;);
    }


<span class="nc bnc" id="L136" title="All 2 branches missed.">    for(CoreMap sent: allSentences){</span>
      // check for entity mentions of the same type that are adjacent
<span class="nc" id="L138">      countAdjacentMentions(sent);</span>
      // count relations between two proper nouns
<span class="nc" id="L140">      countNameRelations(sent);</span>
      // count types of mentions
<span class="nc" id="L142">      countMentionTypes(sent);</span>
<span class="nc" id="L143">    }</span>
    if (VERBOSE) {
      printCounter(adjacentEntityMentions, &quot;adjacent entity mention&quot;);
      printCounter(nameRelationCounts, &quot;name relation mention&quot;);
      printCounter(mentionTypeCounts, &quot;mention type counts&quot;);
    }

<span class="nc" id="L150">    return corpus;</span>
  }

  private void countMentionTypes(CoreMap sent) {
<span class="nc" id="L154">    List&lt;EntityMention&gt; mentions = sent.get(MachineReadingAnnotations.EntityMentionsAnnotation.class);</span>
<span class="nc bnc" id="L155" title="All 2 branches missed.">    if(mentions != null){</span>
<span class="nc bnc" id="L156" title="All 2 branches missed.">      for(EntityMention m: mentions){</span>
<span class="nc" id="L157">        mentionTypeCounts.incrementCount(m.getMentionType());</span>
<span class="nc" id="L158">      }</span>
    }
<span class="nc" id="L160">  }</span>

  private void countNameRelations(CoreMap sent) {
<span class="nc" id="L163">    List&lt;RelationMention&gt; mentions = sent.get(MachineReadingAnnotations.RelationMentionsAnnotation.class);</span>
<span class="nc bnc" id="L164" title="All 2 branches missed.">    if(mentions != null){</span>
<span class="nc bnc" id="L165" title="All 2 branches missed.">      for(RelationMention m: mentions) {</span>
<span class="nc" id="L166">        List&lt;EntityMention&gt; args = m.getEntityMentionArgs();</span>
<span class="nc bnc" id="L167" title="All 6 branches missed.">        if(args.size() == 2 &amp;&amp; args.get(0).getMentionType().equals(&quot;NAM&quot;) &amp;&amp; args.get(1).getMentionType().equals(&quot;NAM&quot;)){</span>
<span class="nc" id="L168">          nameRelationCounts.incrementCount(m.getType() + &quot;.&quot; + m.getSubType());</span>
        }
<span class="nc" id="L170">      }</span>
    }
<span class="nc" id="L172">  }</span>

  private void countAdjacentMentions(CoreMap sent) {
<span class="nc" id="L175">    List&lt;EntityMention&gt; mentions = sent.get(MachineReadingAnnotations.EntityMentionsAnnotation.class);</span>
<span class="nc bnc" id="L176" title="All 2 branches missed.">    if(mentions != null){</span>
<span class="nc bnc" id="L177" title="All 2 branches missed.">      for(EntityMention m1: mentions){</span>
<span class="nc bnc" id="L178" title="All 2 branches missed.">        for(EntityMention m2: mentions){</span>
<span class="nc bnc" id="L179" title="All 2 branches missed.">          if(m1 == m2) continue;</span>
<span class="nc bnc" id="L180" title="All 4 branches missed.">          if(m1.getHeadTokenEnd() == m2.getHeadTokenStart() &amp;&amp; m1.getType().equals(m2.getType())){</span>
<span class="nc" id="L181">            adjacentEntityMentions.incrementCount(m1.getType());</span>
          }
<span class="nc" id="L183">        }</span>
<span class="nc" id="L184">      }</span>
    }
<span class="nc" id="L186">  }</span>

  // todo: Change to use a counters print method (get sorting for free!)
  private void printCounter(Counter&lt;String&gt; c, String h) {
<span class="nc" id="L190">    StringBuilder b = new StringBuilder();</span>
<span class="nc" id="L191">    b.append(h).append(&quot; counts:\n&quot;);</span>
<span class="nc" id="L192">    Set&lt;String&gt; keys = c.keySet();</span>
<span class="nc bnc" id="L193" title="All 2 branches missed.">    for(String k: keys){</span>
<span class="nc" id="L194">      b.append(&quot;\t&quot;).append(k).append(&quot;: &quot;).append(c.getCount(k)).append(&quot;\n&quot;);</span>
<span class="nc" id="L195">    }</span>
<span class="nc" id="L196">    logger.info(b.toString());</span>
<span class="nc" id="L197">  }</span>

   /**
   * Reads in a single ACE*.apf.xml file and convert it to RelationSentence
   * objects. However, you probably should call parse() instead.
   *
   * @param file A file object of an ACE file
   * @return list of RelationSentence objects
   */
  private List&lt;CoreMap&gt; readDocument(File file, Annotation corpus) throws IOException, SAXException,
      ParserConfigurationException {
    // remove the extension to make it into a prefix
<span class="nc" id="L209">    String aceFilename = file.getAbsolutePath().replace(&quot;.apf.xml&quot;, &quot;&quot;);</span>
<span class="nc" id="L210">    List&lt;CoreMap&gt; sentencesFromFile = readDocument(aceFilename, corpus);</span>
<span class="nc" id="L211">    return sentencesFromFile;</span>
  }

  /**
   * Reads in a single ACE*.apf.xml file and convert it to RelationSentence
   * objects. However, you probably should call parse() instead.
   *
   * @param prefix prefix of ACE filename to read (e.g.
   *          &quot;/u/mcclosky/scr/data/ACE2005/english_test/bc/CNN_CF_20030827.1630.01&quot;
   *          ) (no &quot;.apf.xml&quot; extension)
   * @return list of RelationSentence objects
   */
  private List&lt;CoreMap&gt; readDocument(String prefix, Annotation corpus) throws IOException, SAXException,
      ParserConfigurationException {
<span class="nc" id="L225">    logger.info(&quot;Reading document: &quot; + prefix);</span>
<span class="nc" id="L226">    List&lt;CoreMap&gt; results = new ArrayList&lt;&gt;();</span>
    AceDocument aceDocument;
<span class="nc bnc" id="L228" title="All 2 branches missed.">    if(aceVersion.equals(&quot;ACE2004&quot;)){</span>
<span class="nc" id="L229">      aceDocument = AceDocument.parseDocument(prefix, false, aceVersion);</span>
    } else {
<span class="nc" id="L231">      aceDocument = AceDocument.parseDocument(prefix, false);</span>
    }
<span class="nc" id="L233">    String docId = aceDocument.getId();</span>

    // map entity mention ID strings to their EntityMention counterparts
<span class="nc" id="L236">    Map&lt;String, EntityMention&gt; entityMentionMap = Generics.newHashMap();</span>

    /*
    for (int sentenceIndex = 0; sentenceIndex &lt; aceDocument.getSentenceCount(); sentenceIndex++) {
      List&lt;AceToken&gt; tokens = aceDocument.getSentence(sentenceIndex);
      StringBuffer b = new StringBuffer();
      for(AceToken t: tokens) b.append(t.getLiteral() + &quot; &quot; );
      logger.info(&quot;SENTENCE: &quot; + b.toString());
    }
    */

<span class="nc" id="L247">    int tokenOffset = 0;</span>
<span class="nc bnc" id="L248" title="All 2 branches missed.">    for (int sentenceIndex = 0; sentenceIndex &lt; aceDocument.getSentenceCount(); sentenceIndex++) {</span>
<span class="nc" id="L249">      List&lt;AceToken&gt; tokens = aceDocument.getSentence(sentenceIndex);</span>

<span class="nc" id="L251">      List&lt;CoreLabel&gt; words = new ArrayList&lt;&gt;();</span>
<span class="nc" id="L252">      StringBuilder textContent = new StringBuilder();</span>
<span class="nc bnc" id="L253" title="All 2 branches missed.">      for(int i = 0; i &lt; tokens.size(); i ++){</span>
<span class="nc" id="L254">        CoreLabel l = new CoreLabel();</span>
<span class="nc" id="L255">        l.setWord(tokens.get(i).getLiteral());</span>
<span class="nc" id="L256">        l.set(CoreAnnotations.ValueAnnotation.class, l.word());</span>
<span class="nc" id="L257">        l.set(CoreAnnotations.CharacterOffsetBeginAnnotation.class, tokens.get(i).getByteStart());</span>
<span class="nc" id="L258">        l.set(CoreAnnotations.CharacterOffsetEndAnnotation.class, tokens.get(i).getByteEnd());</span>
<span class="nc" id="L259">        words.add(l);</span>
<span class="nc bnc" id="L260" title="All 2 branches missed.">        if(i &gt; 0) textContent.append(&quot; &quot;);</span>
<span class="nc" id="L261">        textContent.append(tokens.get(i).getLiteral());</span>
      }

      // skip &quot;sentences&quot; that are really just SGML tags (which come from using the RobustTokenizer)
<span class="nc bnc" id="L265" title="All 2 branches missed.">      if (words.size() == 1) {</span>
<span class="nc" id="L266">        String word = words.get(0).word();</span>
<span class="nc bnc" id="L267" title="All 4 branches missed.">        if (word.startsWith(&quot;&lt;&quot;) &amp;&amp; word.endsWith(&quot;&gt;&quot;)) {</span>
<span class="nc" id="L268">          tokenOffset += tokens.size();</span>
<span class="nc" id="L269">          continue;</span>
        }
      }

<span class="nc" id="L273">      CoreMap sentence = new Annotation(textContent.toString());</span>
<span class="nc" id="L274">      sentence.set(CoreAnnotations.DocIDAnnotation.class, docId);</span>
<span class="nc" id="L275">      sentence.set(CoreAnnotations.TokensAnnotation.class, words);</span>
<span class="nc" id="L276">      logger.info(&quot;Reading sentence: \&quot;&quot; + textContent + &quot;\&quot;&quot;);</span>

<span class="nc" id="L278">      List&lt;AceEntityMention&gt; entityMentions = aceDocument.getEntityMentions(sentenceIndex);</span>
<span class="nc" id="L279">      List&lt;AceRelationMention&gt; relationMentions = aceDocument.getRelationMentions(sentenceIndex);</span>
<span class="nc" id="L280">      List&lt;AceEventMention&gt; eventMentions = aceDocument.getEventMentions(sentenceIndex);</span>

      // convert entity mentions
<span class="nc bnc" id="L283" title="All 2 branches missed.">      for (AceEntityMention aceEntityMention : entityMentions) {</span>
<span class="nc" id="L284">        String corefID=&quot;&quot;;</span>
<span class="nc bnc" id="L285" title="All 2 branches missed.">        for(String entityID : aceDocument.getKeySetEntities()){</span>
<span class="nc" id="L286">          AceEntity e = aceDocument.getEntity(entityID);</span>
<span class="nc bnc" id="L287" title="All 2 branches missed.">          if(e.getMentions().contains(aceEntityMention)){</span>
<span class="nc" id="L288">            corefID = entityID;</span>
<span class="nc" id="L289">            break;</span>
          }
<span class="nc" id="L291">        }</span>
<span class="nc" id="L292">        EntityMention convertedMention = convertAceEntityMention(aceEntityMention, docId, sentence, tokenOffset, corefID);</span>
//        EntityMention convertedMention = convertAceEntityMention(aceEntityMention, docId, sentence, tokenOffset);
<span class="nc" id="L294">        entityCounts.incrementCount(convertedMention.getType());</span>
<span class="nc" id="L295">        logger.info(&quot;CONVERTED MENTION HEAD SPAN: &quot; + convertedMention.getHead());</span>
<span class="nc" id="L296">        logger.info(&quot;CONVERTED ENTITY MENTION: &quot; + convertedMention);</span>
<span class="nc" id="L297">        AnnotationUtils.addEntityMention(sentence, convertedMention);</span>
<span class="nc" id="L298">        entityMentionMap.put(aceEntityMention.getId(), convertedMention);</span>

        // TODO: make Entity objects as needed
<span class="nc" id="L301">      }</span>

      // convert relation mentions
<span class="nc bnc" id="L304" title="All 2 branches missed.">      for (AceRelationMention aceRelationMention : relationMentions) {</span>
<span class="nc" id="L305">        RelationMention convertedMention = convertAceRelationMention(aceRelationMention, docId, sentence, entityMentionMap);</span>
<span class="nc bnc" id="L306" title="All 2 branches missed.">        if(convertedMention != null){</span>
<span class="nc" id="L307">          relationCounts.incrementCount(convertedMention.getType());</span>
<span class="nc" id="L308">          logger.info(&quot;CONVERTED RELATION MENTION: &quot; + convertedMention);</span>
<span class="nc" id="L309">          AnnotationUtils.addRelationMention(sentence, convertedMention);</span>
        }

        // TODO: make Relation objects
<span class="nc" id="L313">      }</span>

      // convert EventMentions
<span class="nc bnc" id="L316" title="All 2 branches missed.">      for(AceEventMention aceEventMention: eventMentions){</span>
<span class="nc" id="L317">        EventMention convertedMention = convertAceEventMention(aceEventMention, docId, sentence, entityMentionMap, tokenOffset);</span>
<span class="nc bnc" id="L318" title="All 2 branches missed.">        if(convertedMention != null){</span>
<span class="nc" id="L319">          eventCounts.incrementCount(convertedMention.getType());</span>
<span class="nc" id="L320">          logger.info(&quot;CONVERTED EVENT MENTION: &quot; + convertedMention);</span>
<span class="nc" id="L321">          AnnotationUtils.addEventMention(sentence, convertedMention);</span>
        }

        // TODO: make Event objects
<span class="nc" id="L325">      }</span>

<span class="nc" id="L327">      results.add(sentence);</span>
<span class="nc" id="L328">      tokenOffset += tokens.size();</span>
    }
<span class="nc" id="L330">    return results;</span>
  }

  private EventMention convertAceEventMention(
      AceEventMention aceEventMention, String docId,
      CoreMap sentence, Map&lt;String, EntityMention&gt; entityMap,
      int tokenOffset) {
<span class="nc" id="L337">    Set&lt;String&gt; roleSet = aceEventMention.getRoles();</span>
<span class="nc" id="L338">    List&lt;String&gt; roles = new ArrayList&lt;&gt;();</span>
<span class="nc bnc" id="L339" title="All 2 branches missed.">    for(String role: roleSet) roles.add(role);</span>
<span class="nc" id="L340">    List&lt;ExtractionObject&gt; convertedArgs = new ArrayList&lt;&gt;();</span>

<span class="nc" id="L342">    int left = Integer.MAX_VALUE;</span>
<span class="nc" id="L343">    int right = Integer.MIN_VALUE;</span>
<span class="nc bnc" id="L344" title="All 2 branches missed.">    for(String role: roles){</span>
<span class="nc" id="L345">      AceEntityMention arg = aceEventMention.getArg(role);</span>
<span class="nc" id="L346">      ExtractionObject o = entityMap.get(arg.getId());</span>
<span class="nc bnc" id="L347" title="All 2 branches missed.">      if(o == null){</span>
<span class="nc" id="L348">        logger.severe(&quot;READER ERROR: Failed to find event argument with id &quot; + arg.getId());</span>
<span class="nc" id="L349">        logger.severe(&quot;This happens because a few event mentions illegally span multiple sentences. Will ignore this mention.&quot;);</span>
<span class="nc" id="L350">        return null;</span>
      }
<span class="nc" id="L352">      convertedArgs.add(o);</span>
<span class="nc bnc" id="L353" title="All 2 branches missed.">      if(o.getExtentTokenStart() &lt; left) left = o.getExtentTokenStart();</span>
<span class="nc bnc" id="L354" title="All 2 branches missed.">      if(o.getExtentTokenEnd() &gt; right) right = o.getExtentTokenEnd();</span>
<span class="nc" id="L355">    }</span>

<span class="nc" id="L357">    AceCharSeq anchor = aceEventMention.getAnchor();</span>
<span class="nc" id="L358">    ExtractionObject anchorObject = new ExtractionObject(</span>
<span class="nc" id="L359">        aceEventMention.getId() + &quot;-anchor&quot;,</span>
        sentence,
<span class="nc" id="L361">        new Span(anchor.getTokenStart() - tokenOffset, anchor.getTokenEnd() + 1 - tokenOffset),</span>
        &quot;ANCHOR&quot;,
        null);

<span class="nc" id="L365">    EventMention em = new EventMention(</span>
<span class="nc" id="L366">        aceEventMention.getId(),</span>
        sentence,
        new Span(left, right),
<span class="nc" id="L369">        aceEventMention.getParent().getType(),</span>
<span class="nc" id="L370">        aceEventMention.getParent().getSubtype(),</span>
        anchorObject,
        convertedArgs,
        roles);
<span class="nc" id="L374">    return em;</span>
  }

  private RelationMention convertAceRelationMention(AceRelationMention aceRelationMention, String docId,
      CoreMap sentence, Map&lt;String, EntityMention&gt; entityMap) {
<span class="nc" id="L379">    List&lt;AceRelationMentionArgument&gt; args = Arrays.asList(aceRelationMention.getArgs());</span>
<span class="nc" id="L380">    List&lt;ExtractionObject&gt; convertedArgs = new ArrayList&lt;&gt;();</span>
<span class="nc" id="L381">    List&lt;String&gt; argNames = new ArrayList&lt;&gt;();</span>

    // the arguments are already stored in semantic order. Make sure we preserve the same ordering!
<span class="nc" id="L384">    int left = Integer.MAX_VALUE;</span>
<span class="nc" id="L385">    int right = Integer.MIN_VALUE;</span>
<span class="nc bnc" id="L386" title="All 2 branches missed.">    for (AceRelationMentionArgument arg : args) {</span>
<span class="nc" id="L387">      ExtractionObject o = entityMap.get(arg.getContent().getId());</span>
<span class="nc bnc" id="L388" title="All 2 branches missed.">      if(o == null){</span>
<span class="nc" id="L389">        logger.severe(&quot;READER ERROR: Failed to find relation argument with id &quot; + arg.getContent().getId());</span>
<span class="nc" id="L390">        logger.severe(&quot;This happens because a few relation mentions illegally span multiple sentences. Will ignore this mention.&quot;);</span>
<span class="nc" id="L391">        return null;</span>
      }
<span class="nc" id="L393">      convertedArgs.add(o);</span>
<span class="nc" id="L394">      argNames.add(arg.getRole());</span>
<span class="nc bnc" id="L395" title="All 2 branches missed.">      if(o.getExtentTokenStart() &lt; left) left = o.getExtentTokenStart();</span>
<span class="nc bnc" id="L396" title="All 2 branches missed.">      if(o.getExtentTokenEnd() &gt; right) right = o.getExtentTokenEnd();</span>
<span class="nc" id="L397">    }</span>

<span class="nc bnc" id="L399" title="All 6 branches missed.">    if(argNames.size() != 2 || ! argNames.get(0).equalsIgnoreCase(&quot;arg-1&quot;) || ! argNames.get(1).equalsIgnoreCase(&quot;arg-2&quot;)){</span>
<span class="nc" id="L400">      logger.severe(&quot;READER ERROR: Invalid succession of arguments in relation mention: &quot; + argNames);</span>
<span class="nc" id="L401">      logger.severe(&quot;ACE relations must have two arguments. Will ignore this mention.&quot;);</span>
<span class="nc" id="L402">      return null;</span>
    }

<span class="nc" id="L405">    RelationMention relation = new RelationMention(</span>
<span class="nc" id="L406">        aceRelationMention.getId(),</span>
        sentence,
        new Span(left, right),
<span class="nc" id="L409">        aceRelationMention.getParent().getType(),</span>
<span class="nc" id="L410">        aceRelationMention.getParent().getSubtype(),</span>
        convertedArgs,
        null);
<span class="nc" id="L413">    return relation;</span>
  }

  /**
   * Convert an {@link AceEntityMention} to an {@link EntityMention}.
   *
   * @param entityMention {@link AceEntityMention} to convert
   * @param docId ID of the document containing this entity mention
   * @param sentence
   * @param tokenOffset An offset in the calculations of position of the extent to sentence boundary
   *                    (the ace.reader stores absolute token offset from the beginning of the document, but
   *                    we need token offsets from the beginning of the sentence =&gt; adjust by tokenOffset)
   * @return entity as an {@link EntityMention}
   */
  private EntityMention convertAceEntityMention(AceEntityMention entityMention, String docId, CoreMap sentence, int tokenOffset) {
    //log.info(&quot;TYPE is &quot; + entityMention.getParent().getType());
    //log.info(&quot;SUBTYPE is &quot; + entityMention.getParent().getSubtype());
    //log.info(&quot;LDCTYPE is &quot; + entityMention.getLdctype());

<span class="nc" id="L432">    AceCharSeq ext = entityMention.getExtent();</span>
<span class="nc" id="L433">    AceCharSeq head = entityMention.getHead();</span>

<span class="nc" id="L435">    int extStart = ext.getTokenStart() - tokenOffset;</span>
<span class="nc" id="L436">    int extEnd = ext.getTokenEnd() - tokenOffset + 1;</span>
<span class="nc bnc" id="L437" title="All 2 branches missed.">    if (extStart &lt; 0) {</span>
<span class="nc" id="L438">      logger.severe(&quot;READER ERROR: Invalid extent start &quot; + extStart + &quot; for entity mention &quot; + entityMention.getId() + &quot; in document &quot; + docId + &quot; in sentence &quot; + sentence);</span>
<span class="nc" id="L439">      logger.severe(&quot;This may happen due to incorrect EOS detection. Adjusting entity extent.&quot;);</span>
<span class="nc" id="L440">      extStart = 0;</span>
    }
<span class="nc bnc" id="L442" title="All 2 branches missed.">    if (extEnd &gt; sentence.get(CoreAnnotations.TokensAnnotation.class).size()) {</span>
<span class="nc" id="L443">      logger.severe(&quot;READER ERROR: Invalid extent end &quot; + extEnd + &quot; for entity mention &quot; + entityMention.getId() + &quot; in document &quot; + docId + &quot; in sentence &quot; + sentence);</span>
<span class="nc" id="L444">      logger.severe(&quot;This may happen due to incorrect EOS detection. Adjusting entity extent.&quot;);</span>
<span class="nc" id="L445">      extEnd = sentence.get(CoreAnnotations.TokensAnnotation.class).size();</span>
    }

<span class="nc" id="L448">    int headStart = head.getTokenStart() - tokenOffset;</span>
<span class="nc" id="L449">    int headEnd = head.getTokenEnd() - tokenOffset + 1;</span>
<span class="nc bnc" id="L450" title="All 2 branches missed.">    if (headStart &lt; 0) {</span>
<span class="nc" id="L451">      logger.severe(&quot;READER ERROR: Invalid head start &quot; + headStart + &quot; for entity mention &quot; + entityMention.getId() + &quot; in document &quot; + docId + &quot; in sentence &quot; + sentence);</span>
<span class="nc" id="L452">      logger.severe(&quot;This may happen due to incorrect EOS detection. Adjusting entity head span.&quot;);</span>
<span class="nc" id="L453">      headStart = 0;</span>
    }
<span class="nc bnc" id="L455" title="All 2 branches missed.">    if(headEnd &gt; sentence.get(CoreAnnotations.TokensAnnotation.class).size()){</span>
<span class="nc" id="L456">      logger.severe(&quot;READER ERROR: Invalid head end &quot; + headEnd + &quot; for entity mention &quot; + entityMention.getId() + &quot; in document &quot; + docId + &quot; in sentence &quot; + sentence);</span>
<span class="nc" id="L457">      logger.severe(&quot;This may happen due to incorrect EOS detection. Adjusting entity head span.&quot;);</span>
<span class="nc" id="L458">      headEnd = sentence.get(CoreAnnotations.TokensAnnotation.class).size();</span>
    }

    // must adjust due to possible incorrect EOS detection
<span class="nc bnc" id="L462" title="All 2 branches missed.">    if(headStart &lt; extStart){</span>
<span class="nc" id="L463">      headStart = extStart;</span>
    }
<span class="nc bnc" id="L465" title="All 2 branches missed.">    if(headEnd &gt; extEnd){</span>
<span class="nc" id="L466">      headEnd = extEnd;</span>
    }
<span class="nc bnc" id="L468" title="All 4 branches missed.">    assert(headStart &lt; headEnd);</span>

    // note: the ace.reader stores absolute token offset from the beginning of the document, but
    //       we need token offsets from the beginning of the sentence =&gt; adjust by tokenOffset
    // note: in ace.reader the end token position is inclusive, but
    //       in our setup the end token position is exclusive =&gt; add 1 to end
<span class="nc" id="L474">    EntityMention converted = new EntityMention(</span>
<span class="nc" id="L475">        entityMention.getId(),</span>
        sentence,
        new Span(extStart, extEnd),
        new Span(headStart, headEnd),
<span class="nc" id="L479">        entityMention.getParent().getType(),</span>
<span class="nc" id="L480">        entityMention.getParent().getSubtype(),</span>
<span class="nc" id="L481">        entityMention.getLdctype());</span>
<span class="nc" id="L482">    return converted;</span>
  }

  private EntityMention convertAceEntityMention(AceEntityMention entityMention, String docId, CoreMap sentence, int tokenOffset, String corefID) {
<span class="nc" id="L486">    EntityMention converted = convertAceEntityMention(entityMention, docId, sentence, tokenOffset);</span>
<span class="nc" id="L487">    converted.setCorefID(corefID);</span>
<span class="nc" id="L488">    return converted;</span>
  }

  // simple testing code
  public static void main(String[] args) throws IOException {
<span class="nc" id="L493">    Properties props = StringUtils.argsToProperties(args);</span>
<span class="nc" id="L494">    AceReader r = new AceReader(new StanfordCoreNLP(props, false), false);</span>
<span class="nc" id="L495">    r.setLoggerLevel(Level.INFO);</span>
<span class="nc" id="L496">    r.parse(&quot;/scr/nlp/data/ACE2005/&quot;);</span>
    // Annotation a = r.parse(&quot;/user/mengqiu/scr/twitter/nlp/corpus_prep/standalone/ar/data&quot;);
    // BasicEntityExtractor.saveCoNLLFiles(&quot;/tmp/conll&quot;, a, false, false);
<span class="nc" id="L499">    log.info(&quot;done&quot;);</span>
<span class="nc" id="L500">  }</span>

}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.7.8.201612092310</span></div></body></html>