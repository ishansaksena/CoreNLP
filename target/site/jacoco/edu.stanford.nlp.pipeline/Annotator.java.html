<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>Annotator.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">Stanford CoreNLP</a> &gt; <a href="index.source.html" class="el_package">edu.stanford.nlp.pipeline</a> &gt; <span class="el_source">Annotator.java</span></div><h1>Annotator.java</h1><pre class="source lang-java linenums">package edu.stanford.nlp.pipeline;

import edu.stanford.nlp.ling.CoreAnnotation;

import java.util.*;

/**
 * This is an interface for adding annotations to a partially annotated
 * Annotation.  In some ways, it is just a glorified function, except
 * that it explicitly operates in-place on Annotation objects.  Annotators
 * should be given to an AnnotationPipeline in order to make
 * annotation pipelines (the whole motivation of this package), and
 * therefore implementers of this interface should be designed to play
 * well with other Annotators and in their javadocs they should
 * explicitly state what annotations they are assuming already exist
 * in the annotation (like parse, POS tag, etc), what keys they are
 * expecting them under (see, for instance, the ones in CoreAnnotations),
 * and what annotations they will add (or modify) and the keys
 * for them as well.  If you would like to look at the code for a
 * relatively simple Annotator, I recommend NERAnnotator.  For a lot
 * of code you could just add the implements directly, but I recommend
 * wrapping instead because I believe that it will help to keep the
 * pipeline code more manageable.
 * &lt;br&gt;
 * An Annotator can also provide a description of what it produces and
 * a description of what it requires to have been produced by using
 * the Requirement objects.  Predefined Requirement objects are
 * provided for most of the core annotators, such as tokenize, ssplit,
 * etc.  The StanfordCoreNLP version of the AnnotationPipeline can
 * enforce requirements, throwing an exception if an annotator does
 * not have all of its prerequisite met.  An Annotator which does not
 * participate in this system can simply return Collections.emptySet()
 * for both requires() and requirementsSatisfied().
 *
 * @author Jenny Finkel
 */
public interface Annotator {

  /**
   * Given an Annotation, perform a task on this Annotation.
   */
  void annotate(Annotation annotation);


  /**
   * Returns a set of requirements for which tasks this annotator can
   * provide.  For example, the POS annotator will return &quot;pos&quot;.
   */
  Set&lt;Class&lt;? extends CoreAnnotation&gt;&gt; requirementsSatisfied();

  /**
   * Returns the set of tasks which this annotator requires in order
   * to perform.  For example, the POS annotator will return
   * &quot;tokenize&quot;, &quot;ssplit&quot;.
   */
  Set&lt;Class&lt;? extends CoreAnnotation&gt;&gt; requires();

  /**
   * These are annotators which StanfordCoreNLP knows how to create.
   * Add new annotators and/or annotators from other groups here!
   */
  String STANFORD_TOKENIZE = &quot;tokenize&quot;;
  String STANFORD_CLEAN_XML = &quot;cleanxml&quot;;
  String STANFORD_SSPLIT = &quot;ssplit&quot;;
  String STANFORD_POS = &quot;pos&quot;;
  String STANFORD_LEMMA = &quot;lemma&quot;;
  String STANFORD_NER = &quot;ner&quot;;
  String STANFORD_REGEXNER = &quot;regexner&quot;;
  String STANFORD_ENTITY_MENTIONS = &quot;entitymentions&quot;;
  String STANFORD_GENDER = &quot;gender&quot;;
  String STANFORD_TRUECASE = &quot;truecase&quot;;
  String STANFORD_PARSE = &quot;parse&quot;;
  String STANFORD_DETERMINISTIC_COREF = &quot;dcoref&quot;;
  String STANFORD_COREF = &quot;coref&quot;;
  String STANFORD_MENTION = &quot;mention&quot;;  // TODO(jebolton) Merge with entitymention
  String STANFORD_RELATION = &quot;relation&quot;;
  String STANFORD_SENTIMENT = &quot;sentiment&quot;;
  String STANFORD_COLUMN_DATA_CLASSIFIER = &quot;cdc&quot;;
  String STANFORD_DEPENDENCIES = &quot;depparse&quot;;
  String STANFORD_NATLOG = &quot;natlog&quot;;
  String STANFORD_OPENIE = &quot;openie&quot;;
  String STANFORD_QUOTE = &quot;quote&quot;;
  String STANFORD_UD_FEATURES = &quot;udfeats&quot;;
  String STANFORD_LINK = &quot;entitylink&quot;;
  String STANFORD_KBP = &quot;kbp&quot;;


  /**
   * A mapping from an annotator to a its default transitive dependencies.
   * Note that this is not guaranteed to be accurate, as properties set in the annotator
   * can change the annotator's dependencies; but, it's a reasonable guess if you're using
   * things out-of-the-box.
   */
  @SuppressWarnings(&quot;ArraysAsListWithZeroOrOneArgument&quot;)
<span class="fc" id="L95">  Map&lt;String, Set&lt;String&gt;&gt; DEFAULT_REQUIREMENTS = new HashMap&lt;String, Set&lt;String&gt;&gt;(){{</span>
<span class="fc" id="L96">    put(STANFORD_TOKENIZE,                 new LinkedHashSet&lt;&gt;(Arrays.asList()));</span>
<span class="fc" id="L97">    put(STANFORD_CLEAN_XML,                new LinkedHashSet&lt;&gt;(Arrays.asList(STANFORD_TOKENIZE)));</span>
<span class="fc" id="L98">    put(STANFORD_SSPLIT,                   new LinkedHashSet&lt;&gt;(Arrays.asList(STANFORD_TOKENIZE)));</span>
<span class="fc" id="L99">    put(STANFORD_POS,                      new LinkedHashSet&lt;&gt;(Arrays.asList(STANFORD_TOKENIZE, STANFORD_SSPLIT)));</span>
<span class="fc" id="L100">    put(STANFORD_LEMMA,                    new LinkedHashSet&lt;&gt;(Arrays.asList(STANFORD_TOKENIZE, STANFORD_SSPLIT, STANFORD_POS)));</span>
<span class="fc" id="L101">    put(STANFORD_NER,                      new LinkedHashSet&lt;&gt;(Arrays.asList(STANFORD_TOKENIZE, STANFORD_SSPLIT, STANFORD_POS, STANFORD_LEMMA)));</span>
<span class="fc" id="L102">    put(STANFORD_REGEXNER,                 new LinkedHashSet&lt;&gt;(Arrays.asList(STANFORD_TOKENIZE, STANFORD_SSPLIT)));</span>
<span class="fc" id="L103">    put(STANFORD_ENTITY_MENTIONS,          new LinkedHashSet&lt;&gt;(Arrays.asList(STANFORD_TOKENIZE, STANFORD_SSPLIT, STANFORD_POS, STANFORD_LEMMA, STANFORD_NER)));</span>
<span class="fc" id="L104">    put(STANFORD_GENDER,                   new LinkedHashSet&lt;&gt;(Arrays.asList(STANFORD_TOKENIZE, STANFORD_SSPLIT, STANFORD_POS, STANFORD_LEMMA, STANFORD_NER)));</span>
<span class="fc" id="L105">    put(STANFORD_TRUECASE,                 new LinkedHashSet&lt;&gt;(Arrays.asList(STANFORD_TOKENIZE, STANFORD_SSPLIT)));</span>
<span class="fc" id="L106">    put(STANFORD_PARSE,                    new LinkedHashSet&lt;&gt;(Arrays.asList(STANFORD_TOKENIZE, STANFORD_SSPLIT)));</span>
<span class="fc" id="L107">    put(STANFORD_DETERMINISTIC_COREF,      new LinkedHashSet&lt;&gt;(Arrays.asList(STANFORD_TOKENIZE, STANFORD_SSPLIT, STANFORD_POS, STANFORD_LEMMA, STANFORD_NER, STANFORD_MENTION, STANFORD_PARSE)));</span>
<span class="fc" id="L108">    put(STANFORD_COREF,                    new LinkedHashSet&lt;&gt;(Arrays.asList(STANFORD_TOKENIZE, STANFORD_SSPLIT, STANFORD_POS, STANFORD_LEMMA, STANFORD_NER, STANFORD_MENTION)));</span>
<span class="fc" id="L109">    put(STANFORD_MENTION,                  new LinkedHashSet&lt;&gt;(Arrays.asList(STANFORD_TOKENIZE, STANFORD_SSPLIT, STANFORD_POS, STANFORD_LEMMA, STANFORD_NER, STANFORD_DEPENDENCIES)));</span>
<span class="fc" id="L110">    put(STANFORD_RELATION,                 new LinkedHashSet&lt;&gt;(Arrays.asList(STANFORD_TOKENIZE, STANFORD_SSPLIT, STANFORD_POS, STANFORD_LEMMA, STANFORD_NER, STANFORD_PARSE, STANFORD_DEPENDENCIES)));</span>
<span class="fc" id="L111">    put(STANFORD_SENTIMENT,                new LinkedHashSet&lt;&gt;(Arrays.asList(STANFORD_TOKENIZE, STANFORD_SSPLIT, STANFORD_POS, STANFORD_PARSE)));</span>
<span class="fc" id="L112">    put(STANFORD_COLUMN_DATA_CLASSIFIER,   new LinkedHashSet&lt;&gt;(Arrays.asList()));</span>
<span class="fc" id="L113">    put(STANFORD_DEPENDENCIES,             new LinkedHashSet&lt;&gt;(Arrays.asList(STANFORD_TOKENIZE, STANFORD_SSPLIT, STANFORD_POS)));</span>
<span class="fc" id="L114">    put(STANFORD_NATLOG,                   new LinkedHashSet&lt;&gt;(Arrays.asList(STANFORD_TOKENIZE, STANFORD_SSPLIT, STANFORD_POS, STANFORD_LEMMA, STANFORD_DEPENDENCIES)));</span>
<span class="fc" id="L115">    put(STANFORD_OPENIE,                   new LinkedHashSet&lt;&gt;(Arrays.asList(STANFORD_TOKENIZE, STANFORD_SSPLIT, STANFORD_POS, STANFORD_LEMMA, STANFORD_DEPENDENCIES, STANFORD_NATLOG)));</span>
<span class="fc" id="L116">    put(STANFORD_QUOTE,                    new LinkedHashSet&lt;&gt;(Arrays.asList(STANFORD_TOKENIZE, STANFORD_SSPLIT)));</span>
<span class="fc" id="L117">    put(STANFORD_UD_FEATURES,              new LinkedHashSet&lt;&gt;(Arrays.asList(STANFORD_TOKENIZE, STANFORD_SSPLIT, STANFORD_POS, STANFORD_DEPENDENCIES)));</span>
<span class="fc" id="L118">    put(STANFORD_LINK,                     new LinkedHashSet&lt;&gt;(Arrays.asList(STANFORD_TOKENIZE, STANFORD_SSPLIT, STANFORD_POS, STANFORD_DEPENDENCIES, STANFORD_LEMMA, STANFORD_NER, STANFORD_ENTITY_MENTIONS)));</span>
<span class="fc" id="L119">    put(STANFORD_KBP,                      new LinkedHashSet&lt;&gt;(Arrays.asList(STANFORD_TOKENIZE, STANFORD_SSPLIT, STANFORD_POS, STANFORD_DEPENDENCIES, STANFORD_LEMMA, STANFORD_NER, STANFORD_MENTION, STANFORD_COREF, STANFORD_REGEXNER)));</span>
<span class="fc" id="L120">  }};</span>

}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.7.8.201612092310</span></div></body></html>