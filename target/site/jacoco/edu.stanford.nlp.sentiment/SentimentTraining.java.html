<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>SentimentTraining.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">Stanford CoreNLP</a> &gt; <a href="index.source.html" class="el_package">edu.stanford.nlp.sentiment</a> &gt; <span class="el_source">SentimentTraining.java</span></div><h1>SentimentTraining.java</h1><pre class="source lang-java linenums">package edu.stanford.nlp.sentiment; 
import edu.stanford.nlp.util.logging.Redwood;

import java.io.File;
import java.text.DecimalFormat;
import java.text.NumberFormat;
import java.util.Arrays;
import java.util.Collections;
import java.util.List;

import edu.stanford.nlp.trees.Tree;
import edu.stanford.nlp.util.Generics;
import edu.stanford.nlp.util.StringUtils;
import edu.stanford.nlp.util.Timing;

public class SentimentTraining  {

  /** A logger for this class */
<span class="nc" id="L19">  private static Redwood.RedwoodChannels log = Redwood.channels(SentimentTraining.class);</span>

<span class="nc" id="L21">  private static final NumberFormat NF = new DecimalFormat(&quot;0.00&quot;);</span>
<span class="nc" id="L22">  private static final NumberFormat FILENAME = new DecimalFormat(&quot;0000&quot;);</span>

<span class="nc" id="L24">  private SentimentTraining() {} // static methods</span>

  public static void executeOneTrainingBatch(SentimentModel model, List&lt;Tree&gt; trainingBatch, double[] sumGradSquare) {
<span class="nc" id="L27">    SentimentCostAndGradient gcFunc = new SentimentCostAndGradient(model, trainingBatch);</span>
<span class="nc" id="L28">    double[] theta = model.paramsToVector();</span>

    // AdaGrad
<span class="nc" id="L31">    double eps = 1e-3;</span>
    // TODO: do we want to iterate multiple times per batch?
<span class="nc" id="L33">    double[] gradf = gcFunc.derivativeAt(theta);</span>
<span class="nc" id="L34">    double currCost = gcFunc.valueAt(theta);</span>
<span class="nc" id="L35">    log.info(&quot;batch cost: &quot; + currCost);</span>
<span class="nc bnc" id="L36" title="All 2 branches missed.">    for (int feature = 0; feature&lt;gradf.length; feature++ ) {</span>
<span class="nc" id="L37">      sumGradSquare[feature] = sumGradSquare[feature] + gradf[feature]*gradf[feature];</span>
<span class="nc" id="L38">      theta[feature] = theta[feature] - (model.op.trainOptions.learningRate * gradf[feature]/(Math.sqrt(sumGradSquare[feature])+eps));</span>
    }

<span class="nc" id="L41">    model.vectorToParams(theta);</span>
<span class="nc" id="L42">  }</span>

  public static void train(SentimentModel model, String modelPath, List&lt;Tree&gt; trainingTrees, List&lt;Tree&gt; devTrees) {
<span class="nc" id="L45">    Timing timing = new Timing();</span>
<span class="nc" id="L46">    long maxTrainTimeMillis = model.op.trainOptions.maxTrainTimeSeconds * 1000;</span>
<span class="nc" id="L47">    int debugCycle = 0;</span>
    // double bestAccuracy = 0.0;

    // train using AdaGrad (seemed to work best during the dvparser project)
<span class="nc" id="L51">    double[] sumGradSquare = new double[model.totalParamSize()];</span>
<span class="nc" id="L52">    Arrays.fill(sumGradSquare, model.op.trainOptions.initialAdagradWeight);</span>

<span class="nc" id="L54">    int numBatches = trainingTrees.size() / model.op.trainOptions.batchSize + 1;</span>
<span class="nc" id="L55">    log.info(&quot;Training on &quot; + trainingTrees.size() + &quot; trees in &quot; + numBatches + &quot; batches&quot;);</span>
<span class="nc" id="L56">    log.info(&quot;Times through each training batch: &quot; + model.op.trainOptions.epochs);</span>
<span class="nc bnc" id="L57" title="All 2 branches missed.">    for (int epoch = 0; epoch &lt; model.op.trainOptions.epochs; ++epoch) {</span>
<span class="nc" id="L58">      log.info(&quot;======================================&quot;);</span>
<span class="nc" id="L59">      log.info(&quot;Starting epoch &quot; + epoch);</span>
<span class="nc bnc" id="L60" title="All 6 branches missed.">      if (epoch &gt; 0 &amp;&amp; model.op.trainOptions.adagradResetFrequency &gt; 0 &amp;&amp;</span>
          (epoch % model.op.trainOptions.adagradResetFrequency == 0)) {
<span class="nc" id="L62">        log.info(&quot;Resetting adagrad weights to &quot; + model.op.trainOptions.initialAdagradWeight);</span>
<span class="nc" id="L63">        Arrays.fill(sumGradSquare, model.op.trainOptions.initialAdagradWeight);</span>
      }

<span class="nc" id="L66">      List&lt;Tree&gt; shuffledSentences = Generics.newArrayList(trainingTrees);</span>
<span class="nc bnc" id="L67" title="All 2 branches missed.">      if (model.op.trainOptions.shuffleMatrices) {</span>
<span class="nc" id="L68">        Collections.shuffle(shuffledSentences, model.rand);</span>
      }
<span class="nc bnc" id="L70" title="All 2 branches missed.">      for (int batch = 0; batch &lt; numBatches; ++batch) {</span>
<span class="nc" id="L71">        log.info(&quot;======================================&quot;);</span>
<span class="nc" id="L72">        log.info(&quot;Epoch &quot; + epoch + &quot; batch &quot; + batch);</span>

        // Each batch will be of the specified batch size, except the
        // last batch will include any leftover trees at the end of
        // the list
<span class="nc" id="L77">        int startTree = batch * model.op.trainOptions.batchSize;</span>
<span class="nc" id="L78">        int endTree = (batch + 1) * model.op.trainOptions.batchSize;</span>
<span class="nc bnc" id="L79" title="All 2 branches missed.">        if (endTree &gt; shuffledSentences.size()) {</span>
<span class="nc" id="L80">          endTree = shuffledSentences.size();</span>
        }

<span class="nc" id="L83">        executeOneTrainingBatch(model, shuffledSentences.subList(startTree, endTree), sumGradSquare);</span>

<span class="nc" id="L85">        long totalElapsed = timing.report();</span>
<span class="nc" id="L86">        log.info(&quot;Finished epoch &quot; + epoch + &quot; batch &quot; + batch + &quot;; total training time &quot; + totalElapsed + &quot; ms&quot;);</span>

<span class="nc bnc" id="L88" title="All 4 branches missed.">        if (maxTrainTimeMillis &gt; 0 &amp;&amp; totalElapsed &gt; maxTrainTimeMillis) {</span>
          // no need to debug output, we're done now
<span class="nc" id="L90">          break;</span>
        }

<span class="nc bnc" id="L93" title="All 6 branches missed.">        if (batch == (numBatches - 1) &amp;&amp; model.op.trainOptions.debugOutputEpochs &gt; 0 &amp;&amp; (epoch + 1) % model.op.trainOptions.debugOutputEpochs == 0) {</span>
<span class="nc" id="L94">          double score = 0.0;</span>
<span class="nc bnc" id="L95" title="All 2 branches missed.">          if (devTrees != null) {</span>
<span class="nc" id="L96">            Evaluate eval = new Evaluate(model);</span>
<span class="nc" id="L97">            eval.eval(devTrees);</span>
<span class="nc" id="L98">            eval.printSummary();</span>
<span class="nc" id="L99">            score = eval.exactNodeAccuracy() * 100.0;</span>
          }

          // output an intermediate model
<span class="nc bnc" id="L103" title="All 2 branches missed.">          if (modelPath != null) {</span>
            String tempPath;
<span class="nc bnc" id="L105" title="All 2 branches missed.">            if (modelPath.endsWith(&quot;.ser.gz&quot;)) {</span>
<span class="nc" id="L106">              tempPath = modelPath.substring(0, modelPath.length() - 7) + &quot;-&quot; + FILENAME.format(debugCycle) + &quot;-&quot; + NF.format(score) + &quot;.ser.gz&quot;;</span>
<span class="nc bnc" id="L107" title="All 2 branches missed.">            } else if (modelPath.endsWith(&quot;.gz&quot;)) {</span>
<span class="nc" id="L108">              tempPath = modelPath.substring(0, modelPath.length() - 3) + &quot;-&quot; + FILENAME.format(debugCycle) + &quot;-&quot; + NF.format(score) + &quot;.gz&quot;;</span>
            } else {
<span class="nc" id="L110">              tempPath = modelPath.substring(0, modelPath.length() - 3) + &quot;-&quot; + FILENAME.format(debugCycle) + &quot;-&quot; + NF.format(score);</span>
            }
<span class="nc" id="L112">            model.saveSerialized(tempPath);</span>
          }

<span class="nc" id="L115">          ++debugCycle;</span>
        }
      }
<span class="nc" id="L118">      long totalElapsed = timing.report();</span>

<span class="nc bnc" id="L120" title="All 4 branches missed.">      if (maxTrainTimeMillis &gt; 0 &amp;&amp; totalElapsed &gt; maxTrainTimeMillis) {</span>
<span class="nc" id="L121">        log.info(&quot;Max training time exceeded, exiting&quot;);</span>
<span class="nc" id="L122">        break;</span>
      }
    }
<span class="nc" id="L125">  }</span>

  public static boolean runGradientCheck(SentimentModel model, List&lt;Tree&gt; trees) {
<span class="nc" id="L128">    SentimentCostAndGradient gcFunc = new SentimentCostAndGradient(model, trees);</span>
<span class="nc" id="L129">    return gcFunc.gradientCheck(model.totalParamSize(), 50, model.paramsToVector());</span>
  }

  /** Trains a sentiment model.
   *  The -trainPath argument points to a labeled sentiment treebank.
   *  The trees in this data will be used to train the model parameters (also to seed the model vocabulary).
   *  The -devPath argument points to a second labeled sentiment treebank.
   *  The trees in this data will be used to periodically evaluate the performance of the model.
   *  We won't train on this data; it will only be used to test how well the model generalizes to unseen data.
   *  The -model argument specifies where to save the learned sentiment model.
   *
   *  @param args Command line arguments
   */
  public static void main(String[] args) {
<span class="nc" id="L143">    RNNOptions op = new RNNOptions();</span>

<span class="nc" id="L145">    String trainPath = &quot;sentimentTreesDebug.txt&quot;;</span>
<span class="nc" id="L146">    String devPath = null;</span>

<span class="nc" id="L148">    boolean runGradientCheck = false;</span>
<span class="nc" id="L149">    boolean runTraining = false;</span>

<span class="nc" id="L151">    boolean filterUnknown = false;</span>

<span class="nc" id="L153">    String modelPath = null;</span>

<span class="nc bnc" id="L155" title="All 2 branches missed.">    for (int argIndex = 0; argIndex &lt; args.length; ) {</span>
<span class="nc bnc" id="L156" title="All 2 branches missed.">      if (args[argIndex].equalsIgnoreCase(&quot;-train&quot;)) {</span>
<span class="nc" id="L157">        runTraining = true;</span>
<span class="nc" id="L158">        argIndex++;</span>
<span class="nc bnc" id="L159" title="All 2 branches missed.">      } else if (args[argIndex].equalsIgnoreCase(&quot;-gradientcheck&quot;)) {</span>
<span class="nc" id="L160">        runGradientCheck = true;</span>
<span class="nc" id="L161">        argIndex++;</span>
<span class="nc bnc" id="L162" title="All 2 branches missed.">      } else if (args[argIndex].equalsIgnoreCase(&quot;-trainpath&quot;)) {</span>
<span class="nc" id="L163">        trainPath = args[argIndex + 1];</span>
<span class="nc" id="L164">        argIndex += 2;</span>
<span class="nc bnc" id="L165" title="All 2 branches missed.">      } else if (args[argIndex].equalsIgnoreCase(&quot;-devpath&quot;)) {</span>
<span class="nc" id="L166">        devPath = args[argIndex + 1];</span>
<span class="nc" id="L167">        argIndex += 2;</span>
<span class="nc bnc" id="L168" title="All 2 branches missed.">      } else if (args[argIndex].equalsIgnoreCase(&quot;-model&quot;)) {</span>
<span class="nc" id="L169">        modelPath = args[argIndex + 1];</span>
<span class="nc" id="L170">        argIndex += 2;</span>
<span class="nc bnc" id="L171" title="All 2 branches missed.">      } else if (args[argIndex].equalsIgnoreCase(&quot;-filterUnknown&quot;)) {</span>
<span class="nc" id="L172">        filterUnknown = true;</span>
<span class="nc" id="L173">        argIndex++;</span>
      } else {
<span class="nc" id="L175">        int newArgIndex = op.setOption(args, argIndex);</span>
<span class="nc bnc" id="L176" title="All 2 branches missed.">        if (newArgIndex == argIndex) {</span>
<span class="nc" id="L177">          throw new IllegalArgumentException(&quot;Unknown argument &quot; + args[argIndex]);</span>
        }
<span class="nc" id="L179">        argIndex = newArgIndex;</span>
<span class="nc" id="L180">      }</span>
    }

    // read in the trees
<span class="nc" id="L184">    List&lt;Tree&gt; trainingTrees = SentimentUtils.readTreesWithGoldLabels(trainPath);</span>
<span class="nc" id="L185">    log.info(&quot;Read in &quot; + trainingTrees.size() + &quot; training trees&quot;);</span>
<span class="nc bnc" id="L186" title="All 2 branches missed.">    if (filterUnknown) {</span>
<span class="nc" id="L187">      trainingTrees = SentimentUtils.filterUnknownRoots(trainingTrees);</span>
<span class="nc" id="L188">      log.info(&quot;Filtered training trees: &quot; + trainingTrees.size());</span>
    }

<span class="nc" id="L191">    List&lt;Tree&gt; devTrees = null;</span>
<span class="nc bnc" id="L192" title="All 2 branches missed.">    if (devPath != null) {</span>
<span class="nc" id="L193">      devTrees = SentimentUtils.readTreesWithGoldLabels(devPath);</span>
<span class="nc" id="L194">      log.info(&quot;Read in &quot; + devTrees.size() + &quot; dev trees&quot;);</span>
<span class="nc bnc" id="L195" title="All 2 branches missed.">      if (filterUnknown) {</span>
<span class="nc" id="L196">        devTrees = SentimentUtils.filterUnknownRoots(devTrees);</span>
<span class="nc" id="L197">        log.info(&quot;Filtered dev trees: &quot; + devTrees.size());</span>
      }
    }

    // TODO: binarize the trees, then collapse the unary chains.
    // Collapsed unary chains always have the label of the top node in
    // the chain
    // Note: the sentiment training data already has this done.
    // However, when we handle trees given to us from the Stanford Parser,
    // we will have to perform this step

    // build an uninitialized SentimentModel from the binary productions
<span class="nc" id="L209">    log.info(&quot;Sentiment model options:\n&quot; + op);</span>
<span class="nc" id="L210">    SentimentModel model = new SentimentModel(op, trainingTrees);</span>

<span class="nc bnc" id="L212" title="All 2 branches missed.">    if (op.trainOptions.initialMatrixLogPath != null) {</span>
<span class="nc" id="L213">      StringUtils.printToFile(new File(op.trainOptions.initialMatrixLogPath), model.toString(), false, false, &quot;utf-8&quot;);</span>
    }

    // TODO: need to handle unk rules somehow... at test time the tree
    // structures might have something that we never saw at training
    // time.  for example, we could put a threshold on all of the
    // rules at training time and anything that doesn't meet that
    // threshold goes into the unk.  perhaps we could also use some
    // component of the accepted training rules to build up the &quot;unk&quot;
    // parameter in case there are no rules that don't meet the
    // threshold

<span class="nc bnc" id="L225" title="All 2 branches missed.">    if (runGradientCheck) {</span>
<span class="nc" id="L226">      runGradientCheck(model, trainingTrees);</span>
    }

<span class="nc bnc" id="L229" title="All 2 branches missed.">    if (runTraining) {</span>
<span class="nc" id="L230">      train(model, modelPath, trainingTrees, devTrees);</span>
<span class="nc" id="L231">      model.saveSerialized(modelPath);</span>
    }
<span class="nc" id="L233">  }</span>

}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.7.8.201612092310</span></div></body></html>