<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>PTBTokenizer.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">Stanford CoreNLP</a> &gt; <a href="index.source.html" class="el_package">edu.stanford.nlp.process</a> &gt; <span class="el_source">PTBTokenizer.java</span></div><h1>PTBTokenizer.java</h1><pre class="source lang-java linenums">package edu.stanford.nlp.process;

// Stanford English Tokenizer -- a deterministic, fast high-quality tokenizer
// Copyright (c) 2002-2016 The Board of Trustees of
// The Leland Stanford Junior University. All Rights Reserved.
//
// This program is free software; you can redistribute it and/or
// modify it under the terms of the GNU General Public License
// as published by the Free Software Foundation; either version 2
// of the License, or (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.
//
// You should have received a copy of the GNU General Public License
// along with this program; if not, write to the Free Software
// Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
//
// For more information, bug reports, fixes, contact:
//    Christopher Manning
//    Dept of Computer Science, Gates 1A
//    Stanford CA 94305-9010
//    USA
//    java-nlp-support@lists.stanford.edu
//    http://nlp.stanford.edu/software/


import java.io.*;
import java.util.*;
import java.util.regex.Matcher;
import java.util.regex.Pattern;
import java.util.regex.PatternSyntaxException;

import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.ling.CoreAnnotations;
import edu.stanford.nlp.ling.Word;
import edu.stanford.nlp.ling.HasWord;
import edu.stanford.nlp.io.IOUtils;
import edu.stanford.nlp.io.RuntimeIOException;
import edu.stanford.nlp.util.Generics;
import edu.stanford.nlp.util.PropertiesUtils;
import edu.stanford.nlp.util.StringUtils;
import edu.stanford.nlp.util.logging.Redwood;


/**
 * A fast, rule-based tokenizer implementation, which produces Penn Treebank
 * style tokenization of English text. It was initially written to conform
 * to Penn Treebank tokenization conventions over ASCII text, but now provides
 * a range of tokenization options over a broader space of Unicode text.
 * It reads raw text and outputs
 * tokens of classes that implement edu.stanford.nlp.trees.HasWord
 * (typically a Word or a CoreLabel). It can
 * optionally return end-of-line as a token.
 * &lt;p&gt;
 * New code is encouraged to use the {@link #PTBTokenizer(Reader,LexedTokenFactory,String)}
 * constructor. The other constructors are historical.
 * You specify the type of result tokens with a
 * LexedTokenFactory, and can specify the treatment of tokens by mainly boolean
 * options given in a comma separated String options
 * (e.g., &quot;invertible,normalizeParentheses=true&quot;).
 * If the String is {@code null} or empty, you get the traditional
 * PTB3 normalization behaviour (i.e., you get ptb3Escaping=true).  If you
 * want no normalization, then you should pass in the String
 * &quot;ptb3Escaping=false&quot;.  The known option names are:
 * &lt;ol&gt;
 * &lt;li&gt;invertible: Store enough information about the original form of the
 *     token and the whitespace around it that a list of tokens can be
 *     faithfully converted back to the original String.  Valid only if the
 *     LexedTokenFactory is an instance of CoreLabelTokenFactory.  The
 *     keys used in it are: TextAnnotation for the tokenized form,
 *     OriginalTextAnnotation for the original string, BeforeAnnotation and
 *     AfterAnnotation for the whitespace before and after a token, and
 *     perhaps CharacterOffsetBeginAnnotation and CharacterOffsetEndAnnotation to record
 *     token begin/after end character offsets, if they were specified to be recorded
 *     in TokenFactory construction.  (Like the String class, begin and end
 *     are done so end - begin gives the token length.) Default is false.
 * &lt;li&gt;tokenizeNLs: Whether end-of-lines should become tokens (or just
 *     be treated as part of whitespace). Default is false.
 * &lt;li&gt;tokenizePerLine: Run the tokenizer separately on each line of a file.
 *     This has the following consequences: (i) A token (currently only SGML tokens)
 *     cannot span multiple lines of the original input, and (ii) The tokenizer will not
 *     examine/wait for input from the next line before deciding tokenization decisions on
 *     this line. The latter property affects treating periods by acronyms as end-of-sentence
 *     markers. Having this true is necessary to stop the tokenizer blocking and waiting
 *     for input after a newline is seen when the previous line ends with an abbreviation. &lt;/li&gt;
 * &lt;li&gt;ptb3Escaping: Enable all traditional PTB3 token transforms
 *     (like parentheses becoming -LRB-, -RRB-).  This is a macro flag that
 *     sets or clears all the options below. (Default setting of the various
 *     properties below that this flag controls is equivalent to it being set
 *     to true.)
 * &lt;li&gt;americanize: Whether to rewrite common British English spellings
 *     as American English spellings. (This is useful if your training
 *     material uses American English spelling, such as the Penn Treebank.)
 *     Default is true.
 * &lt;li&gt;normalizeSpace: Whether any spaces in tokens (phone numbers, fractions
 *     get turned into U+00A0 (non-breaking space).  It's dangerous to turn
 *     this off for most of our Stanford NLP software, which assumes no
 *     spaces in tokens. Default is true.
 * &lt;li&gt;normalizeAmpersandEntity: Whether to map the XML &amp;amp;amp; to an
 *      ampersand. Default is true.
 * &lt;li&gt;normalizeCurrency: Whether to do some awful lossy currency mappings
 *     to turn common currency characters into $, #, or &quot;cents&quot;, reflecting
 *     the fact that nothing else appears in the old PTB3 WSJ.  (No Euro!)
 *     Default is true.
 * &lt;li&gt;normalizeFractions: Whether to map certain common composed
 *     fraction characters to spelled out letter forms like &quot;1/2&quot;.
 *     Default is true.
 * &lt;li&gt;normalizeParentheses: Whether to map round parentheses to -LRB-,
 *     -RRB-, as in the Penn Treebank. Default is true.
 * &lt;li&gt;normalizeOtherBrackets: Whether to map other common bracket characters
 *     to -LCB-, -LRB-, -RCB-, -RRB-, roughly as in the Penn Treebank.
 *     Default is true.
 * &lt;li&gt;asciiQuotes: Whether to map all quote characters to the traditional ' and &quot;.
 *     Default is false.
 * &lt;li&gt;latexQuotes: Whether to map quotes to ``, `, ', '', as in Latex
 *     and the PTB3 WSJ (though this is now heavily frowned on in Unicode).
 *     If true, this takes precedence over the setting of unicodeQuotes;
 *     if both are false, no mapping is done.  Default is true.
 * &lt;li&gt;unicodeQuotes: Whether to map quotes to the range U+2018 to U+201D,
 *     the preferred unicode encoding of single and double quotes.
 *     Default is false.
 * &lt;li&gt;ptb3Ellipsis: Whether to map ellipses to three dots (...), the
 *     old PTB3 WSJ coding of an ellipsis. If true, this takes precedence
 *     over the setting of unicodeEllipsis; if both are false, no mapping
 *     is done. Default is true.
 * &lt;li&gt;unicodeEllipsis: Whether to map dot and optional space sequences to
 *     U+2026, the Unicode ellipsis character. Default is false.
 * &lt;li&gt;ptb3Dashes: Whether to turn various dash characters into &quot;--&quot;,
 *     the dominant encoding of dashes in the PTB3 WSJ. Default is true.
 * &lt;li&gt;keepAssimilations: true to tokenize &quot;gonna&quot;, false to tokenize
 *                        &quot;gon na&quot;.  Default is true.
 * &lt;li&gt;escapeForwardSlashAsterisk: Whether to put a backslash escape in front
 *     of / and * as the old PTB3 WSJ does for some reason (something to do
 *     with Lisp readers??). Default is true.
 * &lt;li&gt;untokenizable: What to do with untokenizable characters (ones not
 *     known to the tokenizer).  Six options combining whether to log a
 *     warning for none, the first, or all, and whether to delete them or
 *     to include them as single character tokens in the output: noneDelete,
 *     firstDelete, allDelete, noneKeep, firstKeep, allKeep.
 *     The default is &quot;firstDelete&quot;.
 * &lt;li&gt;strictTreebank3: PTBTokenizer deliberately deviates from strict PTB3
 *      WSJ tokenization in two cases.  Setting this improves compatibility
 *      for those cases.  They are: (i) When an acronym is followed by a
 *      sentence end, such as &quot;U.K.&quot; at the end of a sentence, the PTB3
 *      has tokens of &quot;Corp&quot; and &quot;.&quot;, while by default PTBTokenizer duplicates
 *      the period returning tokens of &quot;Corp.&quot; and &quot;.&quot;, and (ii) PTBTokenizer
 *      will return numbers with a whole number and a fractional part like
 *      &quot;5 7/8&quot; as a single token, with a non-breaking space in the middle,
 *      while the PTB3 separates them into two tokens &quot;5&quot; and &quot;7/8&quot;.
 *      (Exception: for only &quot;U.S.&quot; the treebank does have the two tokens
 *      &quot;U.S.&quot; and &quot;.&quot; like our default; strictTreebank3 now does that too.)
 *      The default is false.
 *  &lt;li&gt;splitHyphenated: whether or not to tokenize segments of hyphenated words
 *      separately (&quot;school&quot; &quot;-&quot; &quot;aged&quot;, &quot;frog&quot; &quot;-&quot; &quot;lipped&quot;), keeping the exceptions
 *      in Supplementary Guidelines for ETTB 2.0 by Justin Mott, Colin Warner, Ann Bies,
 *      Ann Taylor. Default is false, which maintains old treebank tokenizer behavior.
 * &lt;/ol&gt;
 * &lt;p&gt;
 * A single instance of a PTBTokenizer is not thread safe, as it uses
 * a non-threadsafe JFlex object to do the processing.  Multiple
 * instances can be created safely, though.  A single instance of a
 * PTBTokenizerFactory is also not thread safe, as it keeps its
 * options in a local variable.
 * &lt;/p&gt;
 *
 * @author Tim Grow (his tokenizer is a Java implementation of Professor
 *     Chris Manning's Flex tokenizer, pgtt-treebank.l)
 * @author Teg Grenager (grenager@stanford.edu)
 * @author Jenny Finkel (integrating in invertible PTB tokenizer)
 * @author Christopher Manning (redid API, added many options, maintenance)
 */
public class PTBTokenizer&lt;T extends HasWord&gt; extends AbstractTokenizer&lt;T&gt;  {

  /** A logger for this class */
<span class="fc" id="L178">  private static final Redwood.RedwoodChannels log = Redwood.channels(PTBTokenizer.class);</span>

  // the underlying lexer
  private final PTBLexer lexer;


  /**
   * Constructs a new PTBTokenizer that returns Word tokens and which treats
   * carriage returns as normal whitespace.
   *
   * @param r The Reader whose contents will be tokenized
   * @return A PTBTokenizer that tokenizes a stream to objects of type
   *          {@link Word}
   */
  public static PTBTokenizer&lt;Word&gt; newPTBTokenizer(Reader r) {
<span class="fc" id="L193">    return new PTBTokenizer&lt;&gt;(r, new WordTokenFactory(), &quot;&quot;);</span>
  }


  /**
   * Constructs a new PTBTokenizer that makes CoreLabel tokens.
   * It optionally returns carriage returns
   * as their own token. CRs come back as Words whose text is
   * the value of {@code PTBLexer.NEWLINE_TOKEN}.
   *
   * @param r The Reader to read tokens from
   * @param tokenizeNLs Whether to return newlines as separate tokens
   *         (otherwise they normally disappear as whitespace)
   * @param invertible if set to true, then will produce CoreLabels which
   *         will have fields for the string before and after, and the
   *         character offsets
   * @return A PTBTokenizer which returns CoreLabel objects
   */
  public static PTBTokenizer&lt;CoreLabel&gt; newPTBTokenizer(Reader r, boolean tokenizeNLs, boolean invertible) {
<span class="fc" id="L212">    return new PTBTokenizer&lt;&gt;(r, tokenizeNLs, invertible, false, new CoreLabelTokenFactory());</span>
  }


  /**
   * Constructs a new PTBTokenizer that optionally returns carriage returns
   * as their own token, and has a custom LexedTokenFactory.
   * If asked for, CRs come back as Words whose text is
   * the value of {@code PTBLexer.cr}.  This constructor translates
   * between the traditional boolean options of PTBTokenizer and the new
   * options String.
   *
   * @param r The Reader to read tokens from
   * @param tokenizeNLs Whether to return newlines as separate tokens
   *         (otherwise they normally disappear as whitespace)
   * @param invertible if set to true, then will produce CoreLabels which
   *         will have fields for the string before and after, and the
   *         character offsets
   * @param suppressEscaping If true, all the traditional Penn Treebank
   *         normalizations are turned off.  Otherwise, they all happen.
   * @param tokenFactory The LexedTokenFactory to use to create
   *         tokens from the text.
   */
  private PTBTokenizer(final Reader r,
                       final boolean tokenizeNLs,
                       final boolean invertible,
                       final boolean suppressEscaping,
<span class="fc" id="L239">                       final LexedTokenFactory&lt;T&gt; tokenFactory) {</span>
<span class="fc" id="L240">    StringBuilder options = new StringBuilder();</span>
<span class="pc bpc" id="L241" title="1 of 2 branches missed.">    if (suppressEscaping) {</span>
<span class="nc" id="L242">      options.append(&quot;ptb3Escaping=false&quot;);</span>
    } else {
<span class="fc" id="L244">      options.append(&quot;ptb3Escaping=true&quot;); // i.e., turn on all the historical PTB normalizations</span>
    }
<span class="pc bpc" id="L246" title="1 of 2 branches missed.">    if (tokenizeNLs) {</span>
<span class="nc" id="L247">      options.append(&quot;,tokenizeNLs&quot;);</span>
    }
<span class="pc bpc" id="L249" title="1 of 2 branches missed.">    if (invertible) {</span>
<span class="fc" id="L250">      options.append(&quot;,invertible&quot;);</span>
    }
<span class="fc" id="L252">    lexer = new PTBLexer(r, tokenFactory, options.toString());</span>
<span class="fc" id="L253">  }</span>


  /**
   * Constructs a new PTBTokenizer with a custom LexedTokenFactory.
   * Many options for tokenization and what is returned can be set via
   * the options String. See the class documentation for details on
   * the options String.  This is the new recommended constructor!
   *
   * @param r The Reader to read tokens from.
   * @param tokenFactory The LexedTokenFactory to use to create
   *         tokens from the text.
   * @param options Options to the lexer.  See the extensive documentation
   *         in the class javadoc.  The String may be null or empty,
   *         which means that all traditional PTB normalizations are
   *         done.  You can pass in &quot;ptb3Escaping=false&quot; and have no
   *         normalizations done (that is, the behavior of the old
   *         suppressEscaping=true option).
   */
  public PTBTokenizer(final Reader r,
                      final LexedTokenFactory&lt;T&gt; tokenFactory,
<span class="fc" id="L274">                      final String options) {</span>
<span class="fc" id="L275">    lexer = new PTBLexer(r, tokenFactory, options);</span>
<span class="fc" id="L276">  }</span>


  /**
   * Internally fetches the next token.
   *
   * @return the next token in the token stream, or null if none exists.
   */
  @Override
  @SuppressWarnings(&quot;unchecked&quot;)
  protected T getNext() {
    // if (lexer == null) {
    //   return null;
    // }
    try {
<span class="fc" id="L291">      return (T) lexer.next();</span>
<span class="nc" id="L292">    } catch (IOException e) {</span>
<span class="nc" id="L293">      throw new RuntimeIOException(e);</span>
    }
    // cdm 2007: this shouldn't be necessary: PTBLexer decides for itself whether to return CRs based on the same flag!
    // get rid of CRs if necessary
    // while (!tokenizeNLs &amp;&amp; PTBLexer.cr.equals(((HasWord) token).word())) {
    //   token = (T)lexer.next();
    // }

    // horatio: we used to catch exceptions here, which led to broken
    // behavior and made it very difficult to debug whatever the
    // problem was.
  }

  /**
   * Returns the string literal inserted for newlines when the -tokenizeNLs
   * options is set.
   *
   * @return string literal inserted for &quot;\n&quot;.
   */
<span class="nc" id="L312">  public static String getNewlineToken() { return PTBLexer.NEWLINE_TOKEN; }</span>

  /**
   * Returns a presentable version of the given PTB-tokenized text.
   * PTB tokenization splits up punctuation and does various other things
   * that makes simply joining the tokens with spaces look bad. So join
   * the tokens with space and run it through this method to produce nice
   * looking text. It's not perfect, but it works pretty well.
   * &lt;p&gt;
   * &lt;b&gt;Note:&lt;/b&gt; If your tokens have maintained the OriginalTextAnnotation and
   * the BeforeAnnotation and the AfterAnnotation, then rather than doing
   * this you can actually precisely reconstruct the text they were made
   * from!
   *
   * @param ptbText A String in PTB3-escaped form
   * @return An approximation to the original String
   */
  public static String ptb2Text(String ptbText) {
<span class="fc" id="L330">    StringBuilder sb = new StringBuilder(ptbText.length()); // probably an overestimate</span>
<span class="fc" id="L331">    PTB2TextLexer lexer = new PTB2TextLexer(new StringReader(ptbText));</span>
    try {
<span class="fc bfc" id="L333" title="All 2 branches covered.">      for (String token; (token = lexer.next()) != null; ) {</span>
<span class="fc" id="L334">        sb.append(token);</span>
      }
<span class="nc" id="L336">    } catch (IOException e) {</span>
<span class="nc" id="L337">      throw new RuntimeIOException(e);</span>
<span class="fc" id="L338">    }</span>
<span class="fc" id="L339">    return sb.toString();</span>
  }

  /**
   * Returns a presentable version of a given PTB token. For instance,
   * it transforms -LRB- into (.
   */
  public static String ptbToken2Text(String ptbText) {
<span class="fc" id="L347">    return ptb2Text(' ' + ptbText + ' ').trim();</span>
  }

  /**
   * Writes a presentable version of the given PTB-tokenized text.
   * PTB tokenization splits up punctuation and does various other things
   * that makes simply joining the tokens with spaces look bad. So join
   * the tokens with space and run it through this method to produce nice
   * looking text. It's not perfect, but it works pretty well.
   */
  public static int ptb2Text(Reader ptbText, Writer w) throws IOException {
<span class="nc" id="L358">    int numTokens = 0;</span>
<span class="nc" id="L359">    PTB2TextLexer lexer = new PTB2TextLexer(ptbText);</span>
<span class="nc bnc" id="L360" title="All 2 branches missed.">    for (String token; (token = lexer.next()) != null; ) {</span>
<span class="nc" id="L361">      numTokens++;</span>
<span class="nc" id="L362">      w.write(token);</span>
    }
<span class="nc" id="L364">    return numTokens;</span>
  }

  private static void untok(List&lt;String&gt; inputFileList, List&lt;String&gt; outputFileList, String charset) throws IOException {
<span class="nc" id="L368">    final long start = System.nanoTime();</span>
<span class="nc" id="L369">    int numTokens = 0;</span>
<span class="nc" id="L370">    int sz = inputFileList.size();</span>
<span class="nc bnc" id="L371" title="All 2 branches missed.">    if (sz == 0) {</span>
<span class="nc" id="L372">      Reader r = new InputStreamReader(System.in, charset);</span>
<span class="nc" id="L373">      BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(System.out, charset));</span>
<span class="nc" id="L374">      numTokens = ptb2Text(r, writer);</span>
<span class="nc" id="L375">      writer.close();</span>
<span class="nc" id="L376">    } else {</span>
<span class="nc bnc" id="L377" title="All 2 branches missed.">      for (int j = 0; j &lt; sz; j++) {</span>
<span class="nc" id="L378">        Reader r = IOUtils.readerFromString(inputFileList.get(j), charset);</span>
        BufferedWriter writer;
<span class="nc bnc" id="L380" title="All 2 branches missed.">        if (outputFileList == null) {</span>
<span class="nc" id="L381">          writer = new BufferedWriter(new OutputStreamWriter(System.out, charset));</span>
        } else {
<span class="nc" id="L383">          writer = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(outputFileList.get(j)), charset));</span>
        }
<span class="nc" id="L385">        numTokens += ptb2Text(r, writer);</span>
<span class="nc" id="L386">        writer.close();</span>
<span class="nc" id="L387">        r.close();</span>
      }
    }
<span class="nc" id="L390">    final long duration = System.nanoTime() - start;</span>
<span class="nc" id="L391">    final double wordsPerSec = (double) numTokens / ((double) duration / 1000000000.0);</span>
<span class="nc" id="L392">    System.err.printf(&quot;PTBTokenizer untokenized %d tokens at %.2f tokens per second.%n&quot;, numTokens, wordsPerSec);</span>
<span class="nc" id="L393">  }</span>

  /**
   * Returns a presentable version of the given PTB-tokenized words.
   * Pass in a List of Strings and this method will
   * join the words with spaces and call {@link #ptb2Text(String)} on the
   * output.
   *
   * @param ptbWords A list of String
   * @return A presentable version of the given PTB-tokenized words
   */
  public static String ptb2Text(List&lt;String&gt; ptbWords) {
<span class="nc" id="L405">    return ptb2Text(StringUtils.join(ptbWords));</span>
  }


  /**
   * Returns a presentable version of the given PTB-tokenized words.
   * Pass in a List of Words or a Document and this method will
   * join the words with spaces and call {@link #ptb2Text(String)} on the
   * output. This method will take the word() values to prevent additional
   * text from creeping in (e.g., POS tags).
   *
   * @param ptbWords A list of HasWord objects
   * @return A presentable version of the given PTB-tokenized words
   */
  public static String labelList2Text(List&lt;? extends HasWord&gt; ptbWords) {
<span class="nc" id="L420">    List&lt;String&gt; words = new ArrayList&lt;&gt;();</span>
<span class="nc bnc" id="L421" title="All 2 branches missed.">    for (HasWord hw : ptbWords) {</span>
<span class="nc" id="L422">      words.add(hw.word());</span>
<span class="nc" id="L423">    }</span>

<span class="nc" id="L425">    return ptb2Text(words);</span>
  }


  private static void tok(List&lt;String&gt; inputFileList, List&lt;String&gt; outputFileList, String charset, Pattern parseInsidePattern, String options, boolean preserveLines, boolean dump, boolean lowerCase) throws IOException {
<span class="nc" id="L430">    final long start = System.nanoTime();</span>
<span class="nc" id="L431">    long numTokens = 0;</span>
<span class="nc" id="L432">    int numFiles = inputFileList.size();</span>
<span class="nc bnc" id="L433" title="All 2 branches missed.">    if (numFiles == 0) {</span>
<span class="nc" id="L434">      Reader stdin = IOUtils.readerFromStdin(charset);</span>
<span class="nc" id="L435">      BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(System.out, charset));</span>
<span class="nc" id="L436">      numTokens += tokReader(stdin, writer, parseInsidePattern, options, preserveLines, dump, lowerCase);</span>
<span class="nc" id="L437">      IOUtils.closeIgnoringExceptions(writer);</span>

<span class="nc" id="L439">    } else {</span>
<span class="nc bnc" id="L440" title="All 2 branches missed.">      for (int j = 0; j &lt; numFiles; j++) {</span>
<span class="nc" id="L441">        Reader r = IOUtils.readerFromString(inputFileList.get(j), charset);</span>
<span class="nc bnc" id="L442" title="All 2 branches missed.">        BufferedWriter out = (outputFileList == null) ?</span>
          new BufferedWriter(new OutputStreamWriter(System.out, charset)) :
<span class="nc" id="L444">            new BufferedWriter(new OutputStreamWriter(new FileOutputStream(outputFileList.get(j)), charset));</span>
<span class="nc" id="L445">        numTokens += tokReader(r, out, parseInsidePattern, options, preserveLines, dump, lowerCase);</span>
<span class="nc" id="L446">        r.close();</span>
<span class="nc" id="L447">        IOUtils.closeIgnoringExceptions(out);</span>
      } // end for j going through inputFileList
    }

<span class="nc" id="L451">    final long duration = System.nanoTime() - start;</span>
<span class="nc" id="L452">    final double wordsPerSec = (double) numTokens / ((double) duration / 1000000000.0);</span>
<span class="nc" id="L453">    System.err.printf(&quot;PTBTokenizer tokenized %d tokens at %.2f tokens per second.%n&quot;, numTokens, wordsPerSec);</span>
<span class="nc" id="L454">  }</span>

  private static int tokReader(Reader r, BufferedWriter writer, Pattern parseInsidePattern, String options, boolean preserveLines, boolean dump, boolean lowerCase) throws IOException {
<span class="nc" id="L457">    int numTokens = 0;</span>
<span class="nc" id="L458">    boolean beginLine = true;</span>
<span class="nc bnc" id="L459" title="All 2 branches missed.">    boolean printing = (parseInsidePattern == null); // start off printing, unless you're looking for a start entity</span>
<span class="nc" id="L460">    Matcher m = null;</span>
<span class="nc bnc" id="L461" title="All 2 branches missed.">    if (parseInsidePattern != null) {</span>
<span class="nc" id="L462">      m = parseInsidePattern.matcher(&quot;&quot;); // create once as performance hack</span>
      // System.err.printf(&quot;parseInsidePattern is: |%s|%n&quot;, parseInsidePattern);
    }
<span class="nc bnc" id="L465" title="All 2 branches missed.">    for (PTBTokenizer&lt;CoreLabel&gt; tokenizer = new PTBTokenizer&lt;&gt;(r, new CoreLabelTokenFactory(), options); tokenizer.hasNext(); ) {</span>
<span class="nc" id="L466">      CoreLabel obj = tokenizer.next();</span>
      // String origStr = obj.get(CoreAnnotations.TextAnnotation.class).replaceFirst(&quot;\n+$&quot;, &quot;&quot;); // DanC added this to fix a lexer bug, hopefully now corrected
<span class="nc" id="L468">      String origStr = obj.get(CoreAnnotations.TextAnnotation.class);</span>
      String str;
<span class="nc bnc" id="L470" title="All 2 branches missed.">      if (lowerCase) {</span>
<span class="nc" id="L471">        str = origStr.toLowerCase(Locale.ENGLISH);</span>
<span class="nc" id="L472">        obj.set(CoreAnnotations.TextAnnotation.class, str);</span>
      } else {
<span class="nc" id="L474">        str = origStr;</span>
      }
<span class="nc bnc" id="L476" title="All 4 branches missed.">      if (m != null &amp;&amp; m.reset(origStr).matches()) {</span>
<span class="nc" id="L477">        printing = m.group(1).isEmpty(); // turn on printing if no end element slash, turn it off it there is</span>
        // System.err.printf(&quot;parseInsidePattern matched against: |%s|, printing is %b.%n&quot;, origStr, printing);
<span class="nc bnc" id="L479" title="All 2 branches missed.">      } else if (printing) {</span>
<span class="nc bnc" id="L480" title="All 2 branches missed.">        if (dump) {</span>
          // after having checked for tags, change str to be exhaustive
<span class="nc" id="L482">          str = obj.toShorterString();</span>
        }
<span class="nc bnc" id="L484" title="All 2 branches missed.">        if (preserveLines) {</span>
<span class="nc bnc" id="L485" title="All 2 branches missed.">          if (PTBLexer.NEWLINE_TOKEN.equals(origStr)) {</span>
<span class="nc" id="L486">            beginLine = true;</span>
<span class="nc" id="L487">            writer.newLine();</span>
          } else {
<span class="nc bnc" id="L489" title="All 2 branches missed.">            if ( ! beginLine) {</span>
<span class="nc" id="L490">              writer.write(' ');</span>
            } else {
<span class="nc" id="L492">              beginLine = false;</span>
            }
            // writer.write(str.replace(&quot;\n&quot;, &quot;&quot;));
<span class="nc" id="L495">            writer.write(str);</span>
          }
        } else {
<span class="nc" id="L498">          writer.write(str);</span>
<span class="nc" id="L499">          writer.newLine();</span>
        }
      }
<span class="nc" id="L502">      numTokens++;</span>
<span class="nc" id="L503">    }</span>
<span class="nc" id="L504">    return numTokens;</span>
  }


  /** @return A PTBTokenizerFactory that vends Word tokens. */
  public static TokenizerFactory&lt;Word&gt; factory() {
<span class="fc" id="L510">    return PTBTokenizerFactory.newTokenizerFactory();</span>
  }

  /** @return A PTBTokenizerFactory that vends CoreLabel tokens. */
  public static TokenizerFactory&lt;CoreLabel&gt; factory(boolean tokenizeNLs, boolean invertible) {
<span class="nc" id="L515">    return PTBTokenizerFactory.newPTBTokenizerFactory(tokenizeNLs, invertible);</span>
  }


  /** @return A PTBTokenizerFactory that vends CoreLabel tokens with default tokenization. */
  public static TokenizerFactory&lt;CoreLabel&gt; coreLabelFactory() {
<span class="fc" id="L521">    return coreLabelFactory(&quot;&quot;);</span>
  }

  /** @return A PTBTokenizerFactory that vends CoreLabel tokens with default tokenization. */
  public static TokenizerFactory&lt;CoreLabel&gt; coreLabelFactory(String options) {
<span class="fc" id="L526">    return PTBTokenizerFactory.newPTBTokenizerFactory(new CoreLabelTokenFactory(), options);</span>
  }

  /** Get a TokenizerFactory that does Penn Treebank tokenization.
   *  This is now the recommended factory method to use.
   *
   * @param factory A TokenFactory that determines what form of token is returned by the Tokenizer
   * @param options A String specifying options (see the class javadoc for details)
   * @param &lt;T&gt; The type of the tokens built by the LexedTokenFactory
   * @return A TokenizerFactory that does Penn Treebank tokenization
   */
  public static &lt;T extends HasWord&gt; TokenizerFactory&lt;T&gt; factory(LexedTokenFactory&lt;T&gt; factory, String options) {
<span class="fc" id="L538">    return new PTBTokenizerFactory&lt;&gt;(factory, options);</span>

  }


  /** This class provides a factory which will vend instances of PTBTokenizer
   *  which wrap a provided Reader.  See the documentation for
   *  {@link PTBTokenizer} for details of the parameters and options.
   *
   *  @see PTBTokenizer
   *  @param &lt;T&gt; The class of the returned tokens
   */
  public static class PTBTokenizerFactory&lt;T extends HasWord&gt; implements TokenizerFactory&lt;T&gt; {

    private static final long serialVersionUID = -8859638719818931606L;

    protected final LexedTokenFactory&lt;T&gt; factory;
    protected String options;


    /**
     * Constructs a new TokenizerFactory that returns Word objects and
     * treats carriage returns as normal whitespace.
     * THIS METHOD IS INVOKED BY REFLECTION BY SOME OF THE JAVANLP
     * CODE TO LOAD A TOKENIZER FACTORY.  IT SHOULD BE PRESENT IN A
     * TokenizerFactory.
     *
     * @return A TokenizerFactory that returns Word objects
     */
    public static TokenizerFactory&lt;Word&gt; newTokenizerFactory() {
<span class="fc" id="L568">      return newPTBTokenizerFactory(new WordTokenFactory(), &quot;&quot;);</span>
    }

    /**
     * Constructs a new PTBTokenizer that returns Word objects and
     * uses the options passed in.
     * THIS METHOD IS INVOKED BY REFLECTION BY SOME OF THE JAVANLP
     * CODE TO LOAD A TOKENIZER FACTORY.  IT SHOULD BE PRESENT IN A
     * TokenizerFactory.
     *
     * @param options A String of options
     * @return A TokenizerFactory that returns Word objects
     */
    public static PTBTokenizerFactory&lt;Word&gt; newWordTokenizerFactory(String options) {
<span class="nc" id="L582">      return new PTBTokenizerFactory&lt;&gt;(new WordTokenFactory(), options);</span>
    }

    /**
     * Constructs a new PTBTokenizer that returns CoreLabel objects and
     * uses the options passed in.
     *
     * @param options A String of options. For the default, recommended
     *                options for PTB-style tokenization compatibility, pass
     *                in an empty String.
     * @return A TokenizerFactory that returns CoreLabel objects o
     */
    public static PTBTokenizerFactory&lt;CoreLabel&gt; newCoreLabelTokenizerFactory(String options) {
<span class="fc" id="L595">      return new PTBTokenizerFactory&lt;&gt;(new CoreLabelTokenFactory(), options);</span>
    }

    /**
     * Constructs a new PTBTokenizer that uses the LexedTokenFactory and
     * options passed in.
     *
     * @param tokenFactory The LexedTokenFactory
     * @param options A String of options
     * @return A TokenizerFactory that returns objects of the type of the
     *         LexedTokenFactory
     */
    public static &lt;T extends HasWord&gt; PTBTokenizerFactory&lt;T&gt; newPTBTokenizerFactory(LexedTokenFactory&lt;T&gt; tokenFactory, String options) {
<span class="fc" id="L608">      return new PTBTokenizerFactory&lt;&gt;(tokenFactory, options);</span>
    }

    public static PTBTokenizerFactory&lt;CoreLabel&gt; newPTBTokenizerFactory(boolean tokenizeNLs, boolean invertible) {
<span class="nc" id="L612">      return new PTBTokenizerFactory&lt;&gt;(tokenizeNLs, invertible, false, new CoreLabelTokenFactory());</span>
    }


    // Constructors

    // This one is historical
<span class="nc" id="L619">    private PTBTokenizerFactory(boolean tokenizeNLs, boolean invertible, boolean suppressEscaping, LexedTokenFactory&lt;T&gt; factory) {</span>
<span class="nc" id="L620">      this.factory = factory;</span>
<span class="nc" id="L621">      StringBuilder optionsSB = new StringBuilder();</span>
<span class="nc bnc" id="L622" title="All 2 branches missed.">      if (suppressEscaping) {</span>
<span class="nc" id="L623">        optionsSB.append(&quot;ptb3Escaping=false&quot;);</span>
      } else {
<span class="nc" id="L625">        optionsSB.append(&quot;ptb3Escaping=true&quot;); // i.e., turn on all the historical PTB normalizations</span>
      }
<span class="nc bnc" id="L627" title="All 2 branches missed.">      if (tokenizeNLs) {</span>
<span class="nc" id="L628">        optionsSB.append(&quot;,tokenizeNLs&quot;);</span>
      }
<span class="nc bnc" id="L630" title="All 2 branches missed.">      if (invertible) {</span>
<span class="nc" id="L631">        optionsSB.append(&quot;,invertible&quot;);</span>
      }
<span class="nc" id="L633">      this.options = optionsSB.toString();</span>
<span class="nc" id="L634">    }</span>

    /** Make a factory for PTBTokenizers.
     *
     *  @param tokenFactory A factory for the token type that the tokenizer will return
     *  @param options Options to the tokenizer (see the class documentation for details)
     */
<span class="fc" id="L641">    private PTBTokenizerFactory(LexedTokenFactory&lt;T&gt; tokenFactory, String options) {</span>
<span class="fc" id="L642">      this.factory = tokenFactory;</span>
<span class="fc" id="L643">      this.options = options;</span>
<span class="fc" id="L644">    }</span>


    /** Returns a tokenizer wrapping the given Reader. */
    @Override
    public Iterator&lt;T&gt; getIterator(Reader r) {
<span class="nc" id="L650">      return getTokenizer(r);</span>
    }

    /** Returns a tokenizer wrapping the given Reader. */
    @Override
    public Tokenizer&lt;T&gt; getTokenizer(Reader r) {
<span class="fc" id="L656">      return new PTBTokenizer&lt;&gt;(r, factory, options);</span>
    }

    @Override
    public Tokenizer&lt;T&gt; getTokenizer(Reader r, String extraOptions) {
<span class="nc bnc" id="L661" title="All 4 branches missed.">      if (options == null || options.isEmpty()) {</span>
<span class="nc" id="L662">        return new PTBTokenizer&lt;&gt;(r, factory, extraOptions);</span>
      } else {
<span class="nc" id="L664">        return new PTBTokenizer&lt;&gt;(r, factory, options + ',' + extraOptions);</span>
      }
    }

    @Override
    public void setOptions(String options) {
<span class="nc" id="L670">      this.options = options;</span>
<span class="nc" id="L671">    }</span>
  } // end static class PTBTokenizerFactory

  /**
   * Command-line option specification.
   */
  private static Map&lt;String,Integer&gt; optionArgDefs() {
<span class="nc" id="L678">    Map&lt;String,Integer&gt; optionArgDefs = Generics.newHashMap();</span>
<span class="nc" id="L679">    optionArgDefs.put(&quot;options&quot;, 1);</span>
<span class="nc" id="L680">    optionArgDefs.put(&quot;ioFileList&quot;, 0);</span>
<span class="nc" id="L681">    optionArgDefs.put(&quot;lowerCase&quot;, 0);</span>
<span class="nc" id="L682">    optionArgDefs.put(&quot;dump&quot;, 0);</span>
<span class="nc" id="L683">    optionArgDefs.put(&quot;untok&quot;, 0);</span>
<span class="nc" id="L684">    optionArgDefs.put(&quot;encoding&quot;, 1);</span>
<span class="nc" id="L685">    optionArgDefs.put(&quot;parseInside&quot;, 1);</span>
<span class="nc" id="L686">    optionArgDefs.put(&quot;preserveLines&quot;, 0);</span>
<span class="nc" id="L687">    return optionArgDefs;</span>
  }

  /**
   * Reads files given as arguments and print their tokens, by default as
   * one per line.  This is useful either for testing or to run
   * standalone to turn a corpus into a one-token-per-line file of tokens.
   * This main method assumes that the input file is in utf-8 encoding,
   * unless an encoding is specified.
   * &lt;p/&gt;
   * Usage: {@code java edu.stanford.nlp.process.PTBTokenizer [options] filename+ }
   * &lt;p/&gt;
   * Options:
   * &lt;ul&gt;
   * &lt;li&gt; -options options Set various tokenization options
   *       (see the documentation in the class javadoc)
   * &lt;li&gt; -preserveLines Produce space-separated tokens, except
   *       when the original had a line break, not one-token-per-line
   * &lt;li&gt; -encoding encoding Specifies a character encoding. If you do not
   *      specify one, the default is utf-8 (not the platform default).
   * &lt;li&gt; -lowerCase Lowercase all tokens (on tokenization)
   * &lt;li&gt; -parseInside regex Names an XML-style element or a regular expression
   *      over such elements.  The tokenizer will only tokenize inside elements
   *      that match this regex.  (This is done by regex matching, not an XML
   *      parser, but works well for simple XML documents, or other SGML-style
   *      documents, such as Linguistic Data Consortium releases, which adopt
   *      the convention that a line of a file is either XML markup or
   *      character data but never both.)
   * &lt;li&gt; -ioFileList file* The remaining command-line arguments are treated as
   *      filenames that themselves contain lists of pairs of input-output
   *      filenames (2 column, whitespace separated).
   * &lt;li&gt; -dump Print the whole of each CoreLabel, not just the value (word)
   * &lt;li&gt; -untok Heuristically untokenize tokenized text
   * &lt;li&gt; -h, -help Print usage info
   * &lt;/ul&gt;
   *
   * @param args Command line arguments
   * @throws IOException If any file I/O problem
   */
  public static void main(String[] args) throws IOException {
<span class="nc" id="L727">    Properties options = StringUtils.argsToProperties(args, optionArgDefs());</span>
<span class="nc" id="L728">    boolean showHelp = PropertiesUtils.getBool(options, &quot;help&quot;, false);</span>
<span class="nc" id="L729">    showHelp = PropertiesUtils.getBool(options, &quot;h&quot;, showHelp);</span>
<span class="nc bnc" id="L730" title="All 2 branches missed.">    if (showHelp) {</span>
<span class="nc" id="L731">      log.info(&quot;Usage: java edu.stanford.nlp.process.PTBTokenizer [options]* filename*&quot;);</span>
<span class="nc" id="L732">      log.info(&quot;  options: -h|-help|-options tokenizerOptions|-preserveLines|-lowerCase|-dump|-ioFileList&quot;);</span>
<span class="nc" id="L733">      log.info(&quot;           -encoding encoding|-parseInside regex|-untok&quot;);</span>
<span class="nc" id="L734">      return;</span>
    }

<span class="nc" id="L737">    StringBuilder optionsSB = new StringBuilder();</span>
<span class="nc" id="L738">    String tokenizerOptions = options.getProperty(&quot;options&quot;, null);</span>
<span class="nc bnc" id="L739" title="All 2 branches missed.">    if (tokenizerOptions != null) {</span>
<span class="nc" id="L740">      optionsSB.append(tokenizerOptions);</span>
    }
<span class="nc" id="L742">    boolean preserveLines = PropertiesUtils.getBool(options, &quot;preserveLines&quot;, false);</span>
<span class="nc bnc" id="L743" title="All 2 branches missed.">    if (preserveLines) {</span>
<span class="nc" id="L744">      optionsSB.append(&quot;,tokenizeNLs&quot;);</span>
    }
<span class="nc" id="L746">    boolean inputOutputFileList = PropertiesUtils.getBool(options, &quot;ioFileList&quot;, false);</span>
<span class="nc" id="L747">    boolean lowerCase = PropertiesUtils.getBool(options, &quot;lowerCase&quot;, false);</span>
<span class="nc" id="L748">    boolean dump = PropertiesUtils.getBool(options, &quot;dump&quot;, false);</span>
<span class="nc" id="L749">    boolean untok = PropertiesUtils.getBool(options, &quot;untok&quot;, false);</span>
<span class="nc" id="L750">    String charset = options.getProperty(&quot;encoding&quot;, &quot;utf-8&quot;);</span>
<span class="nc" id="L751">    String parseInsideKey = options.getProperty(&quot;parseInside&quot;, null);</span>
<span class="nc" id="L752">    Pattern parseInsidePattern = null;</span>
<span class="nc bnc" id="L753" title="All 2 branches missed.">    if (parseInsideKey != null) {</span>
      try {
        // We still allow space, but PTBTokenizer will change space to &amp;nbsp; so need to also match it
<span class="nc" id="L756">        parseInsidePattern = Pattern.compile(&quot;&lt;(/?)(?:&quot; + parseInsideKey + &quot;)(?:(?:\\s|\u00A0)[^&gt;]*?)?&gt;&quot;);</span>
<span class="nc" id="L757">      } catch (PatternSyntaxException e) {</span>
        // just go with null parseInsidePattern
<span class="nc" id="L759">      }</span>
    }

    // Other arguments are filenames
<span class="nc" id="L763">    String parsedArgStr = options.getProperty(&quot;&quot;,null);</span>
<span class="nc bnc" id="L764" title="All 2 branches missed.">    String[] parsedArgs = (parsedArgStr == null) ? null : parsedArgStr.split(&quot;\\s+&quot;);</span>

<span class="nc" id="L766">    ArrayList&lt;String&gt; inputFileList = new ArrayList&lt;&gt;();</span>
<span class="nc" id="L767">    ArrayList&lt;String&gt; outputFileList = null;</span>
<span class="nc bnc" id="L768" title="All 4 branches missed.">    if (inputOutputFileList &amp;&amp; parsedArgs != null) {</span>
<span class="nc" id="L769">      outputFileList = new ArrayList&lt;&gt;();</span>
<span class="nc bnc" id="L770" title="All 2 branches missed.">      for (String fileName : parsedArgs) {</span>
<span class="nc" id="L771">        BufferedReader r = IOUtils.readerFromString(fileName, charset);</span>
<span class="nc bnc" id="L772" title="All 2 branches missed.">        for (String inLine; (inLine = r.readLine()) != null; ) {</span>
<span class="nc" id="L773">          String[] fields = inLine.split(&quot;\\s+&quot;);</span>
<span class="nc" id="L774">          inputFileList.add(fields[0]);</span>
<span class="nc bnc" id="L775" title="All 2 branches missed.">          if (fields.length &gt; 1) {</span>
<span class="nc" id="L776">            outputFileList.add(fields[1]);</span>
          } else {
<span class="nc" id="L778">            outputFileList.add(fields[0] + &quot;.tok&quot;);</span>
          }
<span class="nc" id="L780">        }</span>
<span class="nc" id="L781">        r.close();</span>
      }
<span class="nc bnc" id="L783" title="All 2 branches missed.">    } else if (parsedArgs != null) {</span>
      // Concatenate input files into a single output file
<span class="nc" id="L785">      inputFileList.addAll(Arrays.asList(parsedArgs));</span>
    }

<span class="nc bnc" id="L788" title="All 2 branches missed.">    if (untok) {</span>
<span class="nc" id="L789">      untok(inputFileList, outputFileList, charset);</span>
    } else {
<span class="nc" id="L791">      tok(inputFileList, outputFileList, charset, parseInsidePattern, optionsSB.toString(), preserveLines, dump, lowerCase);</span>
    }
<span class="nc" id="L793">  } // end main</span>

} // end PTBTokenizer
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.7.8.201612092310</span></div></body></html>